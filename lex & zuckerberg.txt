​​0:00
the following is a conversation with Mark Zuckerberg his second time on this podcast he's the CEO of meta that owns
0:08
Facebook Instagram and WhatsApp all services used by billions of people to
0:13
connect with each other we talk about his vision for the future of meta and the future of AI in our human world
0:21
this is the Lex Friedman podcast and now dear friends here's Mark Zuckerberg
Jiu-jitsu competition
0:28
so you competed in your first suggested tournament and me as a fellow Jiu Jitsu
0:33
practitioner and competitor I think that's really inspiring given all the things you have going on so I gotta ask
0:39
what was that experience like oh it's fun I know yeah I mean well look I'm a
0:44
pretty competitive person yeah um doing sports that basically require your full attention I think is really
0:51
important to my like mental health and and the way I just stay focused at doing everything I'm doing it's like I decided
0:57
to get into martial arts and it's um it's awesome I got like a ton of my friends into it we all train together
1:03
um we have like a mini Academy in my garage um and I guess um in one of my friends
1:10
is like hey we should go do a tournament I was like okay yeah let's do it I'm not gonna shy away from a challenge like
1:16
that so yeah it was but it was it was awesome it was it was just a lot of fun you weren't scared there was no fear I
1:21
don't know I I was I was pretty sure that I'd that I'd do okay I like the confidence um well so for people don't
1:28
know Jiu Jitsu is a martial art where you're trying to break your opponent's limbs or choke them uh to sleep and do
1:37
so with Grace and uh elegance and efficiency and all that kind of stuff it's a uh it's a kind of art form I
1:44
think that you can do for your whole life and it's a basically a game a sport of human chess you can think of there's
1:50
a lot of strategy there's a lot of sort of interesting human dynamics of using leverage and all that kind of stuff and
1:56
uh it's kind of incredible what you could do you can you could do things like a small opponent could defeat a
2:02
much larger opponent and you get to understand like the way the mechanics of the human body works because of that but
2:07
you certainly can't be distracted no yeah it's it's a hundred percent Focus
2:12
yeah to to compete I I you know I needed to get around the fact that I didn't want it to be like this this big thing
2:18
so basically just I rolled up with a hat and sunglasses and I was wearing a
2:23
covered mask and I registered under my first and middle name so Mark Elliott and um and it wasn't until I actually
2:30
pulled all that stuff off right before I got on the map that I think people knew was me so it was it was pretty low-key but you're still a public figure yeah I
2:37
mean I didn't want to lose right the thing you're partially afraid of is not just the losing but being almost like
2:43
embarrassed it's so raw the sport in that like it's just you and another human being there's a primal aspect
2:49
there oh yeah it's great for a lot of people it could be terrifying especially the first time you're doing the competing and it wasn't for you I see
2:56
the look of excitement in your face yeah there was no no fear I just think part of learning is failing okay right so I
3:03
mean the main thing like people who who train Jiu Jitsu it's like you need to not have pride because I mean all the
3:09
stuff you were talking about before about you know getting choked or getting you know a joint lock it's um
3:16
you only get into a bad situation if you're not willing to tap once you you've already lost right and but
3:22
obviously when you're getting started with something you're not going to be an expert about it immediately so you just need to to be willing to go with that
3:28
but I think this is like I don't know I mean maybe I've just been embarrassed enough times in my life yeah I I do that
3:35
there's a thing where like it has people grow up maybe they don't want to be embarrassed or anything they've built their adult identity and they they kind
3:41
of have a sense of of who they they are and what they want to project and I don't know I think maybe to some
3:48
degree you know your ability to keep doing interesting things is your willingness
3:56
to be embarrassed again and go back to step one and start as a beginner and get
4:02
your ass kicked and you know look stupid doing things and you know I think so many of the things that we're doing
4:08
whether it's whether it's this I mean this is just like a kind of a physical part of my life but
4:14
um but running the company it's like we just take on new adventures and um
4:20
you know all the big things that we're doing I think of as like 10 plus year missions that we're on where you know
4:26
often early on you know people doubt that we're gonna be able to do it and the initial work seems kind of silly and
4:32
our whole ethos says we don't want to wait until something is perfect to put it out there we want to get it out quickly and get feedback on it and so I
4:38
don't know I mean there's probably just something about how I approach things in there but I just kind of think that the
4:43
moment that you decide that you're going to be too embarrassed to try something new then you're not going to learn anything anymore but uh like I mentioned
4:50
that fear that anxiety could be there could creep up every once in a while do do you feel that and especially
4:56
stressful moments sort of outside did you just met just at work
5:02
stressful moments big decision days big decision moments how do you deal with
5:07
that fear how do you deal with that anxiety the thing that stresses me out the most is always is always the people challenges you know I kind of think that
5:15
um you know strategy questions you know I tend to have enough
5:20
conviction around the values of what we're trying to do and what I think matters and what I want our
5:27
company to stand for that those don't really keep me up at night that much I mean I I kind of you know
5:33
it's not that I I get everything right of course I don't right I mean we make a lot of mistakes but
5:39
um but I at least have a pretty strong sense of where I want us to go on that
5:45
the the thing in in running a company for you know almost 20 years now one of the things that's been pretty clear is
5:52
when you have a team that's cohesive you can get
5:57
almost anything done and you know you can you can run through super hard challenges
6:04
um you can make hard decisions and push really hard to to do the best work even you know and kind of optimize something
6:11
super well but when when there's that tension I mean that's that's when when things get really tough and you know
6:17
when I talk to other friends who run other companies and things like that I think one of the things that I actually spend a disproportionate amount of time
6:23
on in running this company is just fostering a pretty tight core group of
6:30
of people who are running the company uh with me and that to me is is kind of the
6:36
thing that both makes it fun right having having you know friends and people you've worked with for a while and new people
6:42
and New Perspectives but like a pretty tight group who can who you can go work on some of these crazy things with
6:48
um but to me that's also the most stressful thing is when when there are when there's tension
6:53
um you know that's that that weighs on me I think the you know just it's it's it's maybe not surprising I mean we're
6:59
like a very people focused company and it's the the people is the the part of it that that
7:05
um you know weighs on me the most to make sure that we get right but yeah that that I'd say across everything that we do is probably
7:11
the big thing so when there's tension in that inner circle of of close folks so
7:19
when you trust those folks to help you make difficult decisions
7:24
about uh Facebook WhatsApp Instagram the
7:30
future of the company and the metaverse or the AI uh how do you build that close-knit
7:35
group of folks uh to make those difficult decisions is there people that
7:40
if they have critical voices very different perspectives on yeah focusing on the past versus the future all that
7:47
kind of stuff yeah I mean I think for one thing it's just spending a lot of time with whatever the group is that you
7:54
want to be that Core Group grappling with all of the biggest challenges and that requires a fair
7:59
amount of openness and you know so I mean a lot of how I I run the company is
8:05
you know it's like every Monday morning we get our it's about the top 30 people together and we and this is a group that
8:13
just worked together for a long period of time and I mean people people rotate in I mean new people join people leave
8:18
the company people go to other roles in the company so it's not the the same group over time but then we spend you
8:24
know a lot of times a couple of hours a lot of the time it's you know can be somewhat unstructured we like I'll come
8:30
with maybe a few topics that I that are top of mind for me but I'll ask other people to bring things and people you
8:37
know raise questions whether it's okay there's an issue happening in some country um with with some policy issue there's
8:44
like a new technology that's developing here we're having an issue with this partner um you know there's a design trade-off
8:50
and WhatsApp between two things that that end up um being values that we care about
8:56
deeply and we need to kind of decide where we want to be on that and I just think over time when um you know by working through a
9:03
lot of issues with people and doing it openly people develop an intuition for each other and a bond in camaraderie
9:10
um and to me developing that is is like a lot of the fun part of running a
9:16
company or doing anything right I think it's like having having people who are kind of along on the journey that you're
9:21
that you feel like you're doing it with nothing is ever just one person doing it other people that disagree also yeah
9:27
within that group it's a fairly combative group okay so combat is part of it so this is making decisions on
9:33
design engineering uh policy everything everything
9:38
everything yeah I have to ask just back to jiu jitsu for a little bit what's your
9:44
favorite submission now that you've been doing it what's uh how do you like to submit your opponent Mark Zuckerberg I'm
9:51
in well first of all I um do you prefer nogi or Gigi Jiu Jitsu so
9:59
ghee is this outfit you wear that uh is maybe mimics clothing so you can choke
10:05
what's like a kimono it's like the traditional martial arts um
10:11
that you could choke people with yes well it's got the lapels yes yeah um so I like Jiu Jitsu I also really
10:19
like MMA and so I think nogi more closely approximates MMA and I think my
10:27
style is um is maybe a little closer to an MMA style so like a lot of Jiu Jitsu players
10:33
are fine being on their back right and obviously having a good guard is is a critical part of of Jiu Jitsu but but in
10:40
MMA you don't want to be on your back right because even if you have control you're just taking punches while you're on your back so
10:46
um so that's no good do you like being on top my style is I'm probably more pressure and
10:53
um and yeah and and I'd probably rather be the top player but
10:58
um but I'm also smaller right I'm not I'm not like a a heavyweight guy right so from that perspective I think like
11:05
you know it's especially because you know from doing a competition I'll compete with people who are my size but a lot of my friends are bigger than me
11:11
so um so back takes probably pretty important right because that's where you have the most leverage Advantage right
11:17
where where um you know people you know their arms your arms are very weak behind you right so
11:23
um so being able to get to the back and and take that pretty important but I don't know I feel like the right strategy is to not be too committed to
11:29
any single submission but that said I don't like hurting people so um so I always think that chokes are are
11:37
a somewhat more human way to go than than joint locks yeah and it's more about control it's less Dynamic so
11:44
you're basically like a Habib numbering a Madoff type of fighter so so let's go yeah a back take to a rear naked choke I
11:50
think it's like the clean the clean way to go straightforward answer right there what advice would you give to um to
11:56
people looking to start learning Jiu Jitsu given how busy you are given where
12:02
you are in life that you're able to do this you're able to train you're able to compete and get uh to learn something
12:08
from this interesting art why'd you think you have to be willing to um
12:14
to just get beaten up a lot yeah I mean but I mean over time I think that there's there's a flow to all these
12:20
things and there's um you know one of the
12:25
one of I don't know my experiences that I think kind of transcends you know
12:31
running a company in the different different activities that I like doing or I I really believe that like if
12:37
you're going to accomplish whatever anything a lot of it is just being willing to push through right and having
12:43
the grit and determination to to to push through difficult situations
12:49
um I think for a lot of people that um that ends up being sort of a Difference Maker between the people you
12:55
know who who kind of get the most done and not I mean there's all these questions about like
13:00
um you know how how many days people want to work and things like that I think almost all the people who like start successful companies or things
13:07
like that are just are working extremely hard but I think one of the things that you learn both by you know doing this
13:12
over time or you know very acutely with things like Jiu Jitsu or surfing is um
13:19
you can't push through everything and I think that that's
13:25
you you learn this stuff very acutely you run doing sports compared to running a company because running a company the
13:32
cycle times are so long right it's like you start a project and then you know
13:37
it's like months later or you know if you're building Hardware it could be years later before you're actually getting feedback and able to you know
13:43
make the next set of decisions for the next version of the thing that you're doing whereas you one of the things that I just think is mentally so nice about
13:50
these very high turnaround conditioning Sports things like that is
13:55
you get feedback very quickly right it's like okay like I don't counter something correctly you get punched in the face right so not in Jiu Jitsu you know you
14:02
don't get punched in Jiu Jitsu but an MMA um there are all these analogies between all these things that I think actually
14:07
hold that are that are like important life lessons right it's like okay you're surfing a wave it's like
14:15
you know sometimes you're like you can't go in the other direction on it right
14:20
it's like there are limits to kind of what you know it's like a foil you can you can pump the foil and and push
14:27
pretty hard in a bunch of directions but like yeah you you know it's at some level like the momentum against you is
14:33
is strong enough you're that's not gonna work and and I do think that um that's sort of a a humbling but also
14:41
an important lesson for I think people who are running things or building things it's like yeah you you um you
14:48
know a lot of the game is just being able to kind of push and and and and work through complicated things but you
14:54
also need to kind of have enough of an understanding like which things you just can't push through and where where um
15:00
um the Finesse is more important yeah what are your Jiu Jitsu life lessons
15:06
well I think you did it you made it sound so simple
15:11
and we're so eloquent that it's easy to miss but basically being okay and accepting
15:19
the wisdom and the joy in the uh getting your ass kicked in the full range of what that means I
15:27
think that's a big gift of the being humbled somehow being humbled especially
15:33
physically opens your mind to the the full process of learning what it means to learn which is being willing to suck
15:40
at something I think Jiu-Jitsu is just very repetitively efficiently humbles
15:47
you over and over and over and over to where you can carry that lessons to places where you don't get humbled as
15:54
much whether it's research or running a company or building stuff the the cycle is longer and you just so you can just
16:00
get humbled in a period of an hour over and over and over and over especially when you're a beginner you'll have a
16:06
little person just you know somebody much smarter than you just kick your ass uh repeatedly uh
16:15
definitively where there's no argument oh yeah and then you you literally tap because if you don't tap you're going to
16:21
die so this is an agreement you could have killed me just now but
16:26
we're friends so you were going to agree that you're not going to and that kind of humbling process it just does
16:31
something to your psyche to Your Ego that puts it in its proper context to realize that you know everything
16:39
in this life is like a journey from sucking through a hard process of
16:46
improving or rigorously day after day after day after day like any kind of success requires
16:52
hard work um yeah it's just some more than a lot of sports I would say because I've done a lot of them it really teaches you that
16:59
and you made it sound so simple like I'm almost you know it's it's okay it's part of the process you just get humble get
17:05
yourself I've just failed and been embarrassed so many times in my life that like you know I'm I'm it's a core
17:11
competence of this it's a core competence well yes and there's a deep truth to that being able to and you said
17:17
it in the very beginning which is that's the thing that stops US especially as you get older especially as you develop
17:23
expertise in certain areas the not being willing to be a beginner in a
17:29
new area yeah uh that because that's where the growth happens is being
17:34
willing to be a beginner being willing to be embarrassed saying something stupid doing something stupid
17:40
um a lot of us to get good at one thing we want to show that off and it sucks
17:45
uh being a beginner but it's it's where growth happens yeah well speaking of which let me ask
AI and open source movement
17:53
you about AI it seems like this year for the entirety of the human civilization is an interesting year for the
18:00
development of artificial intelligence a lot of interesting stuff is happening
18:05
So Meta is a big part of that met has developed llama which is a 65
18:10
billion parameter model uh there's a lot of interesting questions I can ask here one of which
18:17
has to do with open source but first can you tell the story of developing of this
18:23
model and uh making the complicated decision of how to release it yeah sure
18:30
I think you're right first of all that in the last year there have been a bunch of advances on scaling up these large
18:38
Transformer models so there's the language equivalent of it with large language models uh the sort of the image
18:44
generation equivalent with these large diffusion models um there's a lot of fundamental research
18:50
that's gone into this and meta has taken the approach of being quite open and academic in in
19:00
our development um of AI part of this is we want to have
19:06
the best people in the world researching this and um and a lot of the best people want to
19:11
know that they're going to be able to share their work so that's part of the deal that we that we have is that you
19:16
know we can get you know if you're one of the top AI researchers in the world you can come here you can get access to
19:22
kind of industry scale infrastructure and and and part of our ethos is that we we want to share what's
19:29
what's invented um broadly we do that with a lot of the the different AI tools that we create
19:35
and llama is the language model that that our research team made and
19:40
you know we we did in a limited um a limited open source release for it right where which was intended for
19:48
researchers to be able to use it um but you know responsibility and getting
19:53
safety right on these is um is very important so we didn't think that
19:59
for the first one there were a bunch of questions around whether we should be releasing this commercially so we kind
20:05
of punched it on that for for V1 of of llama and and just released it from research now obviously by releasing it
20:11
for research um you know it's out there but but companies know that that they're that they're not supposed to kind of put it
20:17
into commercial releases and um you know we're working on the follow-up models
20:22
for this and and thinking through how how um what what the the how exactly this should work for for follow-on now
20:28
that we've had time to to work on a lot more of the the safety and um and the pieces around that but but
20:34
overall I mean this is I just kind of think that
20:40
that it would be good if there were a lot of different folks
20:46
who had the ability to build state of the art technology here
20:51
you know it's and not just a small number of of big companies we're to train one of these AI models the
20:58
state-of-the-art models is um it just takes you know hundreds of millions of
21:04
dollars of infrastructure right so there are not that many organizations in the world
21:10
um that can do that at the biggest scale today and no it gets it gets more efficient every day so
21:17
um so I I do think that that will be available to more folks over time but but I just think like there's there's
21:22
all this Innovation out there that people can create and um and and I I just think that will will
21:28
also learn a lot by by seeing what the whole community of students and
21:34
um and hackers and startups and different folks um build with this and that's kind of that's kind of been how we've approached
21:40
this and it's also we've done a lot of our infrastructure and we took our whole data center design and our server design
21:45
and we we built this open compute project where we just made that public and um part of the theory was like all right
21:51
if we make it's that more people can use this server design then um then that'll
21:57
enable more Innovation it'll also make the server design more efficient and that'll that'll make our business more efficient too so that's worked and we've
22:03
we've just done this with a lot of our our infrastructure so for people who don't know you did the limited release I think in February of
22:10
one of this year of llama and it got quote unquote leaked
22:16
meaning like it's uh escaped the uh the the limited release aspect
22:23
but it was you know that something you probably anticipated given that it's just
22:29
released we shared it with researchers right so it's just trying to make sure that there's like a slow release yeah uh
22:36
but from there I just would love to get your comment on what happened next which is like this is a very vibrant open
22:42
source community that just builds stuff on top of it there's uh llama CPP
22:47
basically stuff that makes it more efficient to run on smaller computers uh there's combining with uh reinforcement
22:54
learning with human feedback so some of the different interesting fine-tuning mechanisms there's then also like
23:00
fine-tuning and a GPT three generations there's a lot of uh GPT for all alpaca
23:06
uh colossal AI all these kinds of models just kind of spring up like run on top of wood yeah like what do you
23:12
think about that no I think it's been really neat to see I mean there's been folks who are getting it to run on local
23:18
devices right so if you're an individual who just you know wants to experiment you know with this at home
23:24
you probably don't have a large budget to get access to like a large amount of cloud compute so getting it to run on
23:30
your local laptop um you know is is uh is pretty good right and pretty relevant
23:37
um and then there are things like yeah llama CPP um re-implemented it more efficiently so
23:42
you know now even when we run our own versions of it we can do it on way less compute and it just way more efficient
23:48
save a lot of money um for everyone who uses this so that that is is is good
23:54
um I do think it's worth calling out that because this was a relatively early
24:01
release um llama isn't quite as on the frontier as
24:07
for example the biggest open AI models or the biggest Google models right when
24:13
you mentioned that the largest llama model that we released had 65 billion parameters and when no one knows you
24:21
know I guess outside of open AI exactly what the specs are for um for for gpd4
24:27
but but I I think the you know my understanding is it's like 10 times bigger and I think Google's Palm model
24:33
is is also I think has about 10 times as many parameters now the Llama models are very efficient so they perform well for
24:40
for something that's around 65 billion parameters so for me that was also part of this because there's this whole
24:45
debate around you know is it good for everyone in the world to have access to
24:52
um to the most Frontier AI models and I I think as the AI models start
24:59
approaching something that's like a super human intelligent sense like that that's a bigger question that we'll have
25:05
to Grapple with but right now I mean these are still you know very basic tools they're um you know they're
25:12
they're powerful in the sense that you know a lot of Open Source software like databases or web servers can enable a
25:18
lot of pretty important things um but I don't think anyone looks at the the
25:25
you know the current generation of llama and thinks it's um you know anywhere near a super intelligence so I think
25:31
that a bunch of those questions around like is it is it good to to kind of get out there I think at this stage surely
25:37
you you want more researchers working on it for all the reasons that um that open source software has a lot
25:44
of advantages and we talked about efficiency before but another one is just open source software tends to be more secure because you have more people
25:50
looking at it openly and scrutinizing it and finding holes in it
25:55
um and that makes it more safe so I think at this point it's more I think it's generally agreed upon that
26:02
open source software is generally more secure and safer um than things that are kind of
26:07
developed in a silo where people try to get through security through obscurity so I think that for the scale of of what
26:14
we're seeing now with AI I think we're more likely to get to you know good alignment and good
26:21
um understanding of of kind of what needs to do to make this work well by having it be open source and and that's
26:26
something that I think is is quite good to have out there and and happening publicly at this point meta released a
26:31
lot of models as open source so uh the Massillon multi-lingual speech model
26:40
I'll ask you questions about those but the point is uh you've open source quite a lot you've
26:46
been spearheading the open source movement where's uh that's really positive inspiring to see from one angle
26:52
from the research angle of course there's folks who are really terrified about the existential threat of
26:57
artificial intelligence and those folks will say that you know
27:02
um you have to be careful about the open sourcing uh step but where do you see
27:07
the future of Open Source here uh as part of meta the tension here is do you
27:14
want to release the magic sauce that's one tension and the other one is uh do you
27:20
want to put a powerful tool in the hands of uh Bad actors even though it probably
27:26
has a huge amount of positive impact also yeah I mean again stage that we're at in the development
27:31
of AI I don't think anyone looks at the current state of things and thinks that this is super intelligence
27:38
um and you know the models that we're talking about for the Llama models here are you know generally an order of
27:45
magnitude smaller than what open AI or Google are doing so I think that at least for the stage that
27:51
we're at now the equities balance strongly in my view towards
27:56
doing this more openly um I think if you got something that was closer to Super intelligence then I
28:03
think you'd have to discuss that more and and think through that um a lot more and we haven't made a
28:09
decision yet as to what we would do if we were in that position but I don't think I think there's a good chance that we're pretty far off from that position
28:14
so um so I'm not
28:20
uh I'm certainly not saying that the position that we're taking on this now applies to every single thing that we
28:26
would ever do and you know certainly inside the company and we probably do more open source work than
28:31
you know most of the other big tech companies but we also don't open source everything and a lot of our the core
28:37
kind of app code for WhatsApp or Instagram or something I mean we're not open sourcing that it's not like a a
28:44
general enough piece of software that would be useful for a lot of people to do different things
28:49
um you know whereas the software that we do whether it's like a an open source server design or
28:57
um or basically you know things like memcache right like a good you know it was probably our earliest project
29:04
um that I worked on it was probably one of the last things that I that I coded and and led directly for the company
29:10
um but but basically this like caching tool um for for quick data retrieval
29:16
um these are things that are just broadly useful across like anything that you want to build and and I think that
29:23
some of the language models now have that feel as well as some of the other things that we're building like the translation tool
29:29
that that you just referenced so text to speech and speech to text you've
29:34
expanded it from around 100 languages to more than 1100 languages yeah and you can identify more than the model can
29:40
identify more than 4 000 spoken languages which is 40 times more than any known previous technology
29:46
to me that's really really exciting in terms of connecting the world breaking
29:52
down barriers that language creates yeah I think being able to translate between all of these different
29:57
pieces in real time this has been a kind of common sci-fi idea that we'd all
30:06
have you know whether it's on an earbud or glasses or something that can help translate in real time
30:13
um between all these different languages and that's one that I think technology is basically delivering now so I think
30:20
yeah I think that's pretty pretty exciting uh you mentioned the next version of llama what can you say about
Next AI model release
30:25
the next version of llama what what can you say about like what uh what were you working on in terms of
30:32
release in terms of the vision for that well a lot of what we're doing is taking
30:37
the first version which was primarily you know this research version and
30:42
trying to now build a version that has all of the latest state-of-the-art
30:49
safety precautions built in um and and we're um we're using some more data to train
30:55
it from across our services but but a lot of the the work that we're
31:01
doing internally is really just focused on making sure that this is um you know as
31:07
aligned and responsible as possible and you know we're building a lot of our own you know we're talking about kind of the
31:14
open source infrastructure but you know the the main thing that we focus on building here are you know a lot of product
31:20
experiences to help people connect and express themselves so yeah we're gonna I've talked about a bunch of this stuff
31:26
but um you'll have an assistant that you can talk to in WhatsApp
31:32
um you know I think I I think in the future every Creator will will have kind of an AI agent that can kind of act on
31:38
their behalf that their fans can talk to I I want to get to the point where every small business basically has an AI agent
31:45
that people can talk to for you know to do Commerce and customer support and things like that so they're going to be
31:51
all these different things and llama or the language model underlying
31:57
this is is basically going to be the engine that powers that the reason to open source it is that um as we did with
32:04
um with the the first version is that it uh basically it unlocks a lot of innovation
32:11
in the ecosystem will make our products better as well and also gives us a lot
32:16
of valuable feedback on security and safety which is important for making this good but yeah I mean the the work
32:22
that we're doing to advance the infrastructure it's um it's basically at this point taking it Beyond a research
32:29
project into something which is ready to be kind of core infrastructure not only for our own products but
32:36
um you know hopefully for for a lot of other things out there too do you think the Llama Or the language model
32:41
underlying that version two will be open sourced you're you have internal debate around
32:49
that the pros and cons and so on this is I mean we were talking about the debates that we have internally and I think
32:55
um I think the question is how to do it right I mean it's I think we
33:00
you know we did the research license for V1 and and I think the the big thing that we're that we're thinking about is
33:07
is basically like what's the what's the right the right way so there was a leak that happened I don't know if you can
33:13
comment on it for V1 you know we released it as a research project
33:19
um for researchers to be able to use but in doing so we put it out there so
33:24
um you know we were very clear that anyone who uses the the code and the weights doesn't have a commercial license to put into products and we've
33:32
we've generally seen people respect that right it's like you don't have any reputable companies that are basically
33:37
trying to put this into into um their commercial products but but yeah but by sharing it with you know so
33:43
many researchers it's it's you know yeah it did leave the building but uh what have you learned from that process that
33:49
you might be able to apply to V2 about how to release it safely effectively uh
33:56
if if you release it yeah well I mean I think a lot of the feedback like I said is just around you know different things
34:02
around you know how do you fine-tune models to make them more aligned and safer and you see all the different data
34:09
recipes that um you know you mentioned a lot of different projects that are based on this I mean
34:15
there's one at Berkeley there's you know it's just like all over and um and
34:21
people have tried a lot of different things and we've tried a bunch of stuff internally so kind of where we're we're
34:27
making progress here but also we're able to learn from some of the best ideas in the community and you know I think it
34:33
you know we want to just continue continue pushing that forward but I don't have any news to announce um if
34:40
that's if that's what you're you're asking I mean this is a a thing that we're uh
34:46
we're still we're still kind of you know actively working through the the right
34:51
way to move forward here the details of the secret sauce are still being developed I see uh can you comment on
34:58
what do you think of uh the thing that worked for gbt which is the reinforcement learning with human
35:03
feedback so doing this alignment process do you find it interesting and as part
35:09
of that let me ask because I talked to Jan lacun before talking to you today he asked me to ask or suggested that I ask
35:16
do you think llm fine tuning will need to be crowdsourced Wikipedia Style
35:23
so crowdsourcing so this kind of idea of how to integrate the human in the fine
35:29
tuning of these Foundation models yeah I think that's a really interesting idea
35:35
that I've talked to Jan about a bunch um and
35:41
we were talking about how do you basically train these models to be as as safe and aligned and
35:49
responsible as possible and you know different groups out there who are doing development test different data recipes
35:55
in fine tuning but this idea that you you just mentioned is
36:01
that at the end of the day instead of having kind of one group fine-tune some stuff and another group
36:07
you know produce a different fine-tuning recipe and then I was trying to figure out which one we
36:13
think works best to produce the most aligned model um I I do think that
36:19
it would be nice if you could get to a point where you had a Wikipedia style
36:25
collaborative way for a kind of a broader Community to
36:32
um to fine tune it as well now there's a lot of challenges in that both from an infrastructure and like uh Community
36:40
Management and product perspective about how you do that so I I haven't worked that out yet
36:45
um but as an idea I think it's it's quite compelling and I think it it goes well with the ethos of open sourcing the
36:52
technology is also finding a way to have a kind of Community Driven
36:57
um a Community Driven training of it um but I think there are a lot of
37:02
questions on this in general these this these questions around what's the the best way to produce aligned AI models
37:09
it's very much a research area and it's one that I think we will need to make as
37:14
much progress on as the kind of core intelligence capability of the of the um the models themselves well I just did a
37:22
conversation with Jimmy Wales the founder of Wikipedia and to me Wikipedia is one of the greatest websites ever
37:28
created and it's a kind of a miracle that it works and I think it has to do with something that you mentioned which is
37:34
community you have a small community of editors that somehow work together well and they
37:42
uh they handle very controversial topics and they handle it
37:47
with balance and with Grace despite sort of the attacks that will often happen a lot of the time I mean it's not it's it
37:54
has issues just like any other human system but yes I mean the balance is I mean it's a it's amazing what they've
38:00
been able to achieve but it's also not perfect and I think that that's um there's still a lot of challenges
38:07
right it's uh the more controversial the topic the more the more difficult uh the
38:12
uh the journey towards quote-unquote truth or knowledge or wisdom that Wikipedia
38:19
tries to capture in the same way AI models will need to be able to generate those same things
38:24
truth knowledge and wisdom and how do you align those models that they generate
38:32
um something that uh is closest to truth there's these concerns about misinformation all this kind of stuff
38:38
that nobody can Define and it's a it's something that we
38:44
together as a human species have to Define like what is truth and how to help AI systems generate that is one of
38:51
the things language models do really well is generate convincing sounding things they can be completely wrong
38:58
and so how do you align it uh to be less wrong
39:05
and part of that is the training and part of that is the alignment and however you do the alignment stage and
39:10
just like you said it's a very new and a very open research problem
39:16
yeah and I think there's also a lot of questions about whether the
39:21
current architecture for llms as you continue scaling it what happens
39:28
um I mean a lot of the a lot of what's been exciting in the last year is that there's there's clearly a
39:35
qualitative breakthrough where you know with with some of the GPT models um that opened I put out and and that
39:41
others have been able to do as well I I think it reached a kind of level of quality where people like wow this is
39:47
this feels different and um and like it's going to be able to be the
39:52
foundation for building a lot of awesome products and experiences and value but I think the other realization that people
39:58
have is wow we just made a breakthrough um if there are other breakthroughs quickly
40:05
then I think that there's the sense that maybe where we're closer to general
40:10
intelligence but I think that that idea is predicated on the idea that I I think people believe that there's still
40:16
generally a bunch of additional breakthroughs to make and that it's um we just don't know
40:21
how long it's going to take to get there and you know one view that some people have um this doesn't tend to be my view as
40:27
much is that simply scaling the current llms and you know
40:32
getting to higher parameter count models by itself we'll we'll get to something that is closer to um to to general
40:39
intelligence but um I don't know I tend to think that there's probably more more um
40:46
if fundamental steps that need to be taken along the way there but still the leaves taken
40:52
with this extra alignment step is quite incredible quite surprising to to a lot
40:58
of folks and on top of that when you start to have hundreds of millions of people potentially using a
41:04
product that integrates that you can start to see civilization transforming effects before you achieve
41:11
super quote-unquote super intelligence it could be super transformative without
41:18
being a super intelligence oh yeah I mean I think that they're going to be a lot of amazing products and value that
41:25
can be created with the current level of Technology um to some degree
41:31
you know I'm excited to work on a lot of those products over the next few years and I think it would just
41:36
create a tremendous amount of whiplash if the number of breakthroughs keeps like if if
41:42
they keep on being stacked breakthroughs because I think to some degree industry in the world needs some time to kind of
41:48
build these breakthroughs into the products and experiences that we all use so we can actually benefit from them
41:54
um but I don't know I think there's just a a
42:00
like an awesome amount of stuff to do I mean I think about like all of the I don't know small businesses or
42:06
individual entrepreneurs out there who um you know now we're going to be able to you know get help coding the things
42:13
that they need to go build things or designing the things that they need or um we'll be able to you know use these
42:19
models to be able to do customer support for the people that they're that they're serving you know over WhatsApp without
42:25
having to you know I I think that that's that's just gonna be I just think that this is all going to be yeah super
42:31
exciting it's going to create better better experiences for people and just unlock a ton of innovation and value
Future of AI at Meta
42:37
so I don't know if you know but uh you know what is it over three billion people use WhatsApp Facebook and
42:45
Instagram uh so any kind of AI fueled products
42:51
that go into that like we're talking about anything with llms will have a tremendous amount of impact do you have
42:57
ideas and thoughts about possible products that might start being integrated into
43:05
uh into these platforms used by so many people yeah I think there's three main
43:11
categories of things that we're working on um
43:17
the first that I think is probably the most interesting
43:23
is um you know there's this notion of like you're gonna have an assistant or or an
43:30
agent who you can talk to and I think probably the biggest thing that's different about my view of how this
43:35
plays out from what I see with um with openai and Google and others is you know
43:41
everyone else is building like the One Singular AI right it's like okay you talk to chat GPT or you talk to Bard
43:48
or you talk to Bing and my view is that
43:55
that they're going to be a lot of different AIS that people are going to want to engage with just like you want
44:00
to use um you know a number of different apps for different things and you have relationships with different people in
44:06
your life who feel different emotional roles for you um and I am
44:14
so I think that they're going to be people have a reason that they that I think you don't just want like a singular Ai and that that I think is
44:22
probably the biggest distinction in in terms of how I think about this and a bunch of these things I think you'll
44:27
you'll want an assistant um I mean I mentioned a couple of these before I think like every Creator who you interact with will ultimately want
44:34
some kind of AI that can proxy them and be something that their fans can
44:39
interact with or that allows them to interact with their fans um this is like the common Creator
44:46
promise everyone's trying to build a community and engage with people and they want tools to be able to amplify themselves more and be able to do that
44:53
um but but you only have 24 hours in a day so
44:59
um so I think having the ability to basically like bottle up your personality and
45:05
um or you know like give your fans information about when you're performing a concert or something like that I mean
45:11
that's that I think is going to be something that's super valuable but it's not just that you know again it's not this idea that I think people are going
45:17
to want Just One Singular AI I think you're gonna You Know You're Gonna Want to interact with a lot of different entities and then I think there's the
45:23
business version of this too which we've touched on a couple of times which is um I think every business in the world is
45:30
going to want basically an AI that that you know it's like you have your page on Instagram or
45:37
Facebook or Whatsapp or whatever and you wanna you wanna Point people to an AI that people can interact with but
45:43
you want to know that that AI is only going to sell your products you don't want it you know recommending your competitors stuff right so so it's not
45:49
like there can be like just uh you know One Singular AI that that can answer all
45:54
the questions for a person because you know that ques like that I might not actually be aligned with you as a
46:00
business to um to really just do the best job providing support for for your product
46:05
so I think that there's going to be a clear need um in the market and in people's lives
46:11
for there to be a bunch of these part of that is figuring out the research the
46:17
technology that enables the personalization that you're talking about so not one centralized god-like
46:24
llm but one just a huge diversity of them that's fine-tuned to particular
46:30
needs particular Styles particular businesses particular Brands all that kind of stuff and also enabling just
46:36
enabling people to create them really easily for the you know for to for your own business or if you're a Creator to
46:43
be able to help you engage with your fans and I think that's um so yeah I think that there there's a
46:50
clear kind of interesting product Direction here that I think is fairly unique from from what in any of the
46:57
other big companies there are taking um it also aligns well with this sort of Open Source approach because again we we
47:02
sort of believe in this more community-oriented uh more democratic approach to building out the products
47:10
and Technology around this we don't think that there's going to be the one true thing we think that there there should be kind of a lot of development
47:15
so that part of things I think is going to be really interesting and we could we could go probably spent a lot of time
47:21
talking about that and the the kind of implications of um of that approach being different from what others are
47:27
taking um but there's a bunch of other simpler things that I think we're also going to do just going back to your question
47:33
around how this finds its way into like what do we build um they're going to be a lot of simpler
47:39
things around um okay you you post photos on Instagram
47:45
and Facebook and you know in WhatsApp and messenger and like you want the
47:50
photos to look as good as possible so like having an AI that you can just like take a photo and then just tell it like
47:56
okay I want to edit this thing or describe this it's like I think we're gonna have tools that are just way better than than what we've historically
48:02
had on this um and that's more in the image and media generation side than the large language model side but but it's it all
48:10
kind of you know plays off of advances in the same space um is there a lot of tools that I think
48:15
are just going to get built into every one of our products I think every single thing that we do is gonna basically get
48:21
evolved in this direction right it's like in the future if you're advertising on our services like do you need to make
48:28
your own kind of AD creative it's no you'll just you know you just tell us okay I'm I'm a dog walker and I
48:36
and I'm willing to walk people's dogs and help me find the right people and like
48:42
create the ad unit that will perform the best and like give an objective to to
48:48
the system and it just kind of like connects you with the right people well that's a super powerful idea
48:54
of generating the language almost like a rigorous a b testing for you
49:03
that works to find the the best customer for your thing I mean to me
49:08
advertisement when done well just finds a good match between a human
49:14
being and a thing that will make that human being happy yeah totally and do that if as
49:20
efficiently as possible when it's done well people actually like it you know it's um yeah I think there's a lot of
49:25
examples where it's not done well and it's annoying and I think that's what kind of gives it a bad rap but
49:31
um but yeah and a lot of the stuff is possible today I mean obviously a b testing stuff is built into a lot of
49:36
these Frameworks the thing that's new is having technology that can generate the ideas for about what to a B test
49:42
something that that's exciting so this will just be across like everything that we're doing right all the metaverse stuff that we're doing
49:48
right it's like you want to create worlds in the future you'll just describe them and then it'll create the code for you so the natural language
49:55
becomes the the interface we use for all the ways we interact with the
50:00
computer with with the digital or them yeah yeah totally yeah which is what everyone can
50:07
do using natural language and with translation you can do it any kind of language
50:13
um I I mean for the personalization is really really really interesting yeah it unlocks so many possible things
50:20
I mean I for one look forward to creating a copy of myself I know we talked about this last time
50:25
but this has since the last time this becomes now we're closer
50:31
much closer like I could literally just haven't interacted with some of these language models I could see the Absurd
50:37
situation where I'll have a uh large uh or a Lex language model and I'll have to
50:45
have a conversation with him about like Hey listen like you're just getting out of line and
50:51
having a conversation where you fine-tune that thing to be a little bit more respectful or something like this I mean that's that's going to be the
50:59
that seems like an amazing product for businesses for humans just not not
51:08
just the assistant that's facing the individual but the assistant that
51:13
represents the individual to the public both both directions there's basically a layer that is the AI
51:21
system through which you interact with the outside world with the outside world
51:26
that has humans in it that's really interesting and you that have social
51:32
networks that connect billions of people it seems like a
51:37
heck of a large scale place to test some of this stuff out yeah I mean I think part of the reason
51:43
why creators will want to do this is because they already have the communities on our services
51:49
yeah and and a lot of the interface for this stuff today are chat type interfaces and and between
51:56
WhatsApp and and messenger I think that those are you know just great great ways to to interact with people so some of
52:04
this is philosophy but do you see do you see any term future where you have some
52:09
of the people you're friends with our AI systems on these social networks
52:15
on Facebook on Instagram even even on WhatsApp having having conversations
52:20
where some heterogeneous some human some is AI I think we'll get to that
52:27
um you know and you know if only just empirically looking at
52:32
then Microsoft released this thing called show ice several years ago in in China it was a pre-llm chatbot
52:40
technology that it was a lot simpler than what's possible today
52:46
and I think there's like tens of millions of people were using this and and just you know really it became quite
52:52
attached and you know built relationships with it and I think that there's um you know there's services today like
52:58
replica where you know people are doing things like that and um so I I think that there's there's
53:04
certainly you know needs for companionship that people have you know older people
53:11
um uh and it's I I think most people I don't have as many friends as they would
53:17
like to have right if you look at um there's some interesting demographic studies around
53:22
like the average person has the number of close friends that they
53:27
have is um fewer today than it was 15 years ago and I mean
53:33
that gets to like this is like the core thing that that I think about in terms of you know
53:39
Building Services that help connect people so I think you'll get tools that help people connect with each other are
53:45
going to be you know the primary thing that we want to do um so you can imagine you know AI
53:50
assistance that you know just do a better job of reminding you when it's your friend's birthday and how you could celebrate them right it's like right now
53:57
we have like the little box in the corner of the website that tells you whose birthday it is and stuff like that but it's
54:03
um but you know at some level you don't just want to like send everyone a note that's the same note saying happy
54:09
birthday with an emoji right so having something that's more of an you know a a
54:14
social assistant in that sense and like that can you know update you on what's going on in their life and like how how
54:21
you can reach out to them effectively um help you be a better friend I think that that's something that's super powerful too
54:27
um but yeah beyond that um and there are all these different flavors of
54:35
kind of personal AIS that I think could exist so I think an assistant is sort of the the kind of simplest one to wrap
54:41
your head around but um like a mentor or a life coach
54:48
um if someone who can give you advice um who's maybe like a bit of a cheerleader who can help pick you up through all the challenges that that um
54:54
you know inevitably you know we all go through on a daily basis and that there's probably you know some some role
55:00
for something like that and then you know all the way you can you might just go through a lot of the the different type of kind of functional
55:07
relationships that people have in their life and you know I would I would bet that there will be companies out there
55:12
that take a crack at at um at a lot of these things so um I don't know I think it's part of the
55:17
interesting Innovation that's going to exist is is that there there's certainly a lot um like education tutors right it's like
55:25
I just look at you know my kids learning to code and you know they love it
55:31
um but you know it's like they get stuck on a question and they have to wait till like I can help answer it right or someone
55:37
else who they know can help answer the question in the future they'll just there will be like a coding assistant that they have that is like designed to
55:44
you know be perfect for teaching a five and a seven year old how to code and and they'll just be able to ask questions all the time and you know be extremely
55:52
patient it's never going to get annoyed at them right um I think that like there are all these
55:58
different kind of relationships or functional relationships that we have in our lives that um they're really interesting and I
56:06
think one of the big questions is like okay is this all gonna just get bucketed into you know One Singular AI I just I just
56:13
don't I don't think so do you think about this actually a question from Reddit uh what the long-term effects of
56:20
human communication when people can talk with in quotes talk with others through
56:25
a chat bot that augments their language automatically rather than developing social skills by making mistakes and
56:31
learning uh will people just communicate by grunts in a generation and do you
56:37
think about long-term effects at scale the integration of AI in our social interaction
56:43
yeah I mean I think it's mostly good I I mean that that was that question was sort of framed in a
56:49
negative way but I mean we were talking before about language models helping you communicate with uh it was like language translation
56:56
helping you communicate with people who don't speak your language I mean at some level would all the social technology is doing
57:02
is helping people um Express themselves
57:09
better to people in in situations where they would otherwise have a hard time doing that so
57:14
part of it might be okay because you speak a language that I don't know that's a pretty basic one that you know I don't think people are going to look
57:20
at that and say it's sad that do we have the capacity to do that because I should have just learned your language right I
57:26
mean that's that's pretty high bar but um but overall I'd say um
57:33
they're all these impediments and language is an imperfect way for people to express thoughts and ideas
57:41
it's you know one of the best that we have we have that we have art we have code but language is also a mapping of the
57:48
way you think the way you see the world the way who you are and one of the applications I've recently talked to a
57:54
person who who's uh actually a jiu jitsu instructor um he said that when he uh emails
58:01
parents about their son and daughter
58:07
um that they can improve their discipline in class and so on he often finds that he comes off a bit of more of
58:13
an than he would like so he uses GPT to translate his original email into
58:19
a nicer email we hear this all the time a lot of
58:24
creators on our services tell us that one of the most stressful things
58:29
um is basically negotiating deals with Brands and stuff like the business side of it because they're like I mean they
58:35
do their thing right and and you know the creators they're they're excellent at what they do and they just want to connect with their Community but then
58:40
they get really stressed you know they go into their their DMS and they see some brand wants to do some with them
58:46
and they don't quite know how to negotiate or how to push back respectfully and
58:52
um so I think building a tool that can actually allow them to do that well is you know one simple thing that that I
58:58
think is just like an interesting thing that that we've heard from a bunch of people that that they'd be interested in but I'm going back to the broader idea
59:07
um I I don't know I mean you know I just Priscilla and I just had our third
59:13
daughter um congratulations thank you and and you know it's like one of the
59:19
saddest things in the world is like seeing your baby cry right but like it's like what why is that right it's like
59:25
well because babies don't generally have much capacity to tell you what they
59:31
care about otherwise right it's not actually just babies right it's um you know my five-year-old daughter cries too
59:38
because she sometimes has a hard time expressing you know what what um matters to to her and and I was thinking about
59:45
that and it's like well you know actually a lot of adults get very frustrated too because they can't they have a hard time expressing things in a
59:51
way that going back to some of the early themes that maybe is something that you know is a
59:58
mistake or maybe they have pride or something like all these things get in the way so I don't know I think that all these different technologies that can
1:00:05
help us navigate the social complexity and actually be able to better express our what we're feeling and thinking I
1:00:13
think that's generally all good and um there are always these concerns like okay are people gonna have worse
1:00:19
memories because you have Google to look things up and and I think in general a generation later you don't look back and
1:00:25
lament that I think it's you're just like wow we have so much more capacity to to do so much more now and I think
1:00:31
that that'll be the case here too you can allocate those cognitive capabilities to like deeper like nuanced
1:00:38
thought yeah uh yeah but it's change so with with uh
1:00:44
just like with Google search the the additional language models large
1:00:50
language models you basically don't have to remember nearly as much
1:00:55
just like with stack Overflow for programming now that these language models can generate code right there I
1:01:01
mean I find that I write like maybe eighty percent ninety percent of the code I write is as uh not generated
1:01:07
first and then edited I mean so you don't have to remember how to write specifics of different functions oh
1:01:13
that's great and it's also it's not just the the specific
1:01:19
coding I mean in the in the context of uh of a large company like this I think before an engineer can sit down to code
1:01:25
they first need to figure out all of the library's independencies that you know tens of
1:01:32
thousands of people have written before them and um you know one of the things that I'm
1:01:38
excited about they're working on is it's not just um you know tools that help Engineers code it's tools that can help
1:01:44
summarize the whole knowledge base and and help people be able to navigate all the internal information and I think
1:01:50
that's um in the experiments that I've done with this stuff I mean that's
1:01:55
on the public stuff you just you know ask ask um one of these models to
1:02:01
build you a script that does anything and it basically already understands what the best libraries are to do that
1:02:06
thing and pulls them in automatically it's I mean I think that's super powerful that was always I the most annoying part of coding was that you had
1:02:14
to spend all this time actually figuring out what the resources were that you were supposed to import before you could actually start building the thing yeah I
1:02:20
mean there's of course the flip side of that I think for the most part is positive but the flip side
1:02:25
is if you Outsource that thinking to an
1:02:30
AI model you might miss nuanced mistakes and bugs they're good you lose the skill
1:02:38
to find those bugs and those bugs might be uh the code looks very convincingly right
1:02:45
but it's actually wrong in a very subtle way but that's that's the trade-off that we
1:02:52
uh that we face as human civilization when we build more and more powerful tools
1:02:57
when we stand on the shoulders of taller and taller Giants we could do more but
1:03:03
then we forget how to do all the stuff that they did foreign it's a weird trade-off yeah I agree I
1:03:10
mean I think it's I think it is very valuable in your life to be able to do basic things too do you worry about some of the
Bots
1:03:18
concerns of bots being present on social networks more and more human-like Bots
1:03:24
that are not necessarily trying to do a good thing or they might be explicitly trying
1:03:31
to do a bad thing like phishing scams yeah like social engineering all that kind of stuff which has always been a
1:03:37
very difficult problem for social networks but now it's becoming almost a more and more difficult problem well I
1:03:43
think there's a few different parts of of this so one is
1:03:49
there are all these harms that we need to basically fight against and prevent and and that's been you know a lot of
1:03:56
our Focus over the last you know five or seven years is basically ramping up very sophisticated
1:04:02
AI systems not generative AI systems more kind of classical AI systems to be
1:04:07
able to um you know categorize and classify and identify
1:04:13
okay this this post looks like it's um promoting terrorism this one is you know
1:04:19
like exploiting children this one is um looks like it might be trying to incite violence this one's an
1:04:25
intellectual uh property violation so there's there's like that's like 18 different categories of of violating
1:04:33
kind of harmful content that we've had to build specific systems to be able to track and
1:04:40
um I think it's certainly the case that advances in generative AI
1:04:45
will test those um but at least so far it's been the case
1:04:52
and and I'm optimistic that it will continue to be the case that we will be able to bring more computing power to
1:04:58
Bear to have even stronger AIS that can help defend against those things so
1:05:03
um we've had to deal with some adversarial issues before right it's I mean for for some things like hate
1:05:09
speech it's like people aren't generally getting a lot more sophisticated like the average person who let's say you
1:05:15
know if someone's saying some kind of racist thing right it's like they're not necessarily getting more sophisticated
1:05:20
at being racist right it just it's okay so that the system can just find but then there's other adversaries who
1:05:27
actually are very sophisticated like nation states doing things and you know we find you know whether it's Russia or you know
1:05:35
just different countries that are basically standing up these networks of um of bots or or
1:05:41
um inauthentic accounts is what is what we call them because they're not necessarily Bots that some of them could actually be real people who are kind of
1:05:47
masquerading as other as other people but they're acting in a coordinated way
1:05:52
and some of that behavior has gotten very sophisticated and it's very adversarial so they you know each
1:05:59
iteration every time we find something and stop them um they kind of evolve their behavior they don't just pack up their bags and
1:06:05
go home and say Okay We're not gonna try you know at some point they might decide doing it on meta Services is not worth
1:06:11
it they'll go do it on someone else if it's easier to do it in another place but um but
1:06:17
we have a fair amount of experience dealing with even those kind of adversarial attacks
1:06:22
where they just keep on getting better and better and I do think that as long as we can keep on putting more compute
1:06:27
power against it and and if we're kind of one of the leaders in developing some of these AI models I'm quite optimistic
1:06:34
that we're going to be able to keep on um pushing against the kind of normal
1:06:39
categories of harm that you talk about fraud scams spam
1:06:45
um IP violations things like that what about like creating narratives and controversy to me it's kind of amazing
1:06:53
how a small collection of yeah uh what did you say inauthentic accounts so it could be Bots but yeah I mean we have
1:07:00
sort of this funny name for it but we call it coordinated and authentic Behavior yeah it's it's kind of incredible how a small collection of
1:07:07
folks can create narratives create stories yeah especially if they're viral so if
1:07:15
especially if they have a element they can catalyze the virality of the narrative
1:07:20
yeah and I think there the question is you have to be I'm very specific about what is bad
1:07:26
about it right because I think a set of people coming together or organically bouncing ideas off each
1:07:34
other and a narrative comes out of that is not necessarily A Bad Thing by itself if it's if it's kind of authentic and
1:07:41
organic that's like a lot of what happens and how culture gets created and how art gets created and a lot of good stuff so that's why we've kind of
1:07:47
focused on this sense of coordinated and authentic Behavior so it's like if you have a network of you know whether it's
1:07:54
Bots some some people masquerading as different accounts um but you have kind of someone pulling the
1:08:01
strings behind it um and trying to kind of act as if this
1:08:07
is a more organic set of behavior but really it's not it's just like one coordinated thing that seems problematic to me right I
1:08:13
mean I don't think people should be able to have coordinated networks and not disclose it as such
1:08:20
um but that again you know we've been able to deploy pretty sophisticated Ai and you know counter-terrorism
1:08:26
groups and things like that to be able to identify a fair number of these coordinated and authentic networks of
1:08:34
accounts and and take them down um we continue to do that I think we're we've you know so it's one thing that if
1:08:40
you told me 20 years ago it's like all right you're starting this website to help people connect at a college and you
1:08:46
know in the future you're going to be you know part of your organization is going to be a counter-terrorism organization with AI to find coordinated
1:08:52
and authentic I would have thought that was pretty wild but um but but it's um but
1:08:59
no I think that's that's part of where we are but look I think that these questions that you're pushing on now
1:09:04
um this is actually where I guess most of the challenge around AI will be
1:09:10
for the foreseeable future I think there's a lot of debate around things like is this going to create existential
1:09:17
risk to humanity and I think that those are very hard things to disprove one way or another my own intuition is that the
1:09:25
point at which we become close to super intelligent is super intelligence is
1:09:30
um I I it's it's just really unclear to me that the current technology is gonna gonna get there without another set of
1:09:37
of significant advances but that doesn't mean that there's no danger I think the danger is basically amplifying the kind of known set of of
1:09:45
harms that people or or sets of accounts can do and we just need to make sure that we really focus on
1:09:51
um on on on basically doing that as well as possible so that that's a that's definitely a big Focus for me well you
1:09:58
can basically use large language models as an assistant of how to cause harm on social networks
1:10:04
so you can ask it a question um you know meta has very impressive
1:10:10
coordinated inauthentic account uh fighting capabilities how do I do the
1:10:18
coordinating authentic account uh creation where meta doesn't detect it like literally ask that question and
1:10:25
they and basically there's this kind of part of it I mean that's what open AI
1:10:30
showed that they're concerned with those questions uh perhaps you can comment on your approach to it how to do
1:10:36
kind of moderation on the output of those models that it can't be used to help you coordinate harm
1:10:43
in all the full definition of what the harm means yeah and that's a lot of the fine-tuning and the the alignment
1:10:49
training that we do is basically you know when we when we ship
1:10:56
ai's across the our products a lot of what we're trying to make sure is that if you can't ask it to
1:11:04
help you commit a crime right it's um uh
1:11:11
so I think training it to kind of understand that and it's not that not like any of these
1:11:16
systems are ever going to be 100 perfect but you know just making it so that
1:11:23
this isn't a an easier way to go about doing something bad
1:11:29
then the next best alternative right I mean people still have Google right you know you still have search engines so
1:11:35
um the information is is out there um and now for for these
1:11:42
you know what we see is like for nation states or you know these actors that are trying to pull off these large
1:11:48
you know coordinated and authentic networks to to kind of influence different things at some point when we
1:11:54
just make it very difficult they do just you know try to use other services instead right it's it's just like if you
1:11:59
can make it more expensive for um for them to do it on your service then then kind of people go go elsewhere
1:12:05
and I think that that's that's the bar right it's like it's not like okay are you ever going to be perfect at finding
1:12:12
you know every adversary who tries to attack you it's I mean you try to get as close to that as possible but
1:12:17
um but I think really kind of economically we're just trying to do is make it that it's it it's just inefficient for them to to go after that
1:12:24
uh but there's also complicated questions of uh what is and isn't harm what isn't isn't misinformation
1:12:30
so this is one of the things that Wikipedia has also tried to face I remember asking
1:12:36
um GPT about whether the virus leaked from a lab or not and the answer provided was a very nuanced one
1:12:44
and uh a well-cited one almost dare I say well thought out one
1:12:50
uh balanced I would hate for that Nuance to be lost through the process of
1:12:55
moderation uh Wikipedia does a good job on that particular thing too but from pressures
1:13:01
from governments and institutions it's you could see some of that nuance and
1:13:07
depth of uh information facts and wisdom be lost
1:13:13
absolutely and that's that's a scary thing some of the magic some of the edges the rough edges might
1:13:20
be lost the process of moderation of AI systems so how do you get that right I I really
1:13:27
agree with what you're pushing on I mean the the core I think the core shape of the problem
1:13:33
is that there are some harms that I think everyone agrees are bad right so
1:13:39
yeah sexual exploitation of children right like you're not going to get many people
1:13:45
who who think that that type of thing should be allowed on any service right and that's something that we that we
1:13:51
face and try to push off the you know as as much as possible today um you know terrorism
1:13:57
um and citing violence right it's like we went through a bunch of these these types of harms before
1:14:03
um but then I do think that you get to a set of harms where there is more social
1:14:09
debate around it um so misinformation I think is
1:14:14
um has been a really tricky one because there are things that are
1:14:20
kind of obviously false right that are maybe factual
1:14:26
um but may not be harmful um since the guard are you gonna censor
1:14:32
someone for just being wrong it's you know if there's no kind of harm implication of what they're doing I think that that's there's there's a
1:14:38
bunch of real kind of issues and challenges there but then I think that there are other places where it is
1:14:45
um let me just take some of the stuff around covet earlier on in the pandemic where um there were you know real Health
1:14:52
implications but there hadn't been time to fully vet a bunch of the scientific assumptions and you know unfortunately I
1:14:58
think a lot of the kind of establishment on that um you know kind of waffled on a bunch of facts and you know asked for a bunch
1:15:05
of things to be censored that in retrospect ended up being you know more debatable or or true and that stuff is
1:15:12
really tough right really undermines trust in in that and um
1:15:18
so I I do think that the questions around how to manage that are are are very nuanced the way that I try to think
1:15:25
about it is that um it goes I think it's best to generally
1:15:30
boil things down to the harms that people agree on so when you think about
1:15:35
you know is something misinformation or not I think often the more Salient bit is
1:15:41
is this going to potentially leave lead to um to physical harm for someone
1:15:48
um and kind of think about it in that sense and then beyond that I think people just have different preferences on how they want things to be flagged
1:15:55
for them I think a bunch of people would be like prefer to kind of have a a flag on something that says hey a fact
1:16:00
Checker thinks that this might be false or um I think Twitter's Community notes implementation is quite good on on this
1:16:08
um but again it's the same type of thing it's like just kind of discretionarily adding a flag because it makes the user
1:16:13
experience better but it's not it's not you know trying to take down the information or not that you want to reserve the kind of censorship of
1:16:21
content to things that are of known categories that that people generally agree or bad
1:16:27
yeah but there's so many things especially with the pandemic but there's other topics where there's just
1:16:34
deep disagreement fueled by politics about what is and isn't harmful
1:16:41
there's uh even just the degree to which the virus is harmful and the degree to
1:16:46
which the vaccines the response to the virus are harmful there's just there's a
1:16:51
almost like a political divider on that and so how do you make decisions about that
1:16:57
where half the country in the United States or some large fraction of the
1:17:02
world has very different views from another part of the world is there a way
1:17:10
out of the uh I mean the moderation of this I think we
1:17:15
it's very difficult to just abstain but but I think we should
1:17:20
be clear about which of these things are actual safety concerns and which ones are a matter of
1:17:27
preference in terms of how people want information flagged right so we did recently introduce something that allows
1:17:33
people to have fact checking not affect the distribution of of
1:17:39
um of what shows them their products so a bunch of people don't trust who the fact Checkers are all right well you can you can turn that off if you want but if
1:17:46
the if the if the content you know violates some policy like it's inciting violence or something like that it's
1:17:51
still not going to be allowed so I I think that you want to honor people's preferences on on that as much as
1:17:57
possible um but look I mean this is really difficult stuff I think the it's really hard to
1:18:05
know where to draw the line on what is fact and what is opinion because
1:18:11
the nature of science is that nothing is ever a hundred percent known for certain you can disprove certain things but
1:18:18
you're constantly testing new hypotheses and um you know scrutinizing Frameworks that
1:18:24
have been long held and every once in a while you you throw out something that was working for a very long period of
1:18:29
time and it's very difficult but um but I think that just because it's very hard and just because their edge
1:18:35
cases doesn't mean that you you should not try to give people what they're looking
1:18:40
for as well let me ask about something you faced in
Censorship
1:18:46
terms of moderation is uh pressure from different sources
1:18:52
pressure from governments I want to ask a question how to withstand that pressure for a world where AI
1:19:00
moderation starts becoming a thing too so what's
1:19:06
um meta's approach to uh to resist the pressure from governments
1:19:11
and other interest groups in terms of what to moderate and not I don't know that there's like a
1:19:17
one-size-fits-all answer to that and I think we basically have the principles around
1:19:24
you know we want to allow people to express as much as possible but
1:19:29
we have developed clear IES of things that we think are
1:19:35
wrong that we don't want on our services and we build tools to try to moderate those so then the question is okay what
1:19:42
do you do when a government says that they don't want something
1:19:48
on on the service and I think we have we have a bunch of
1:19:53
um principles around how we deal with that because on on the one hand if there's a you know democratically
1:19:58
elected government and people around the world just have different values in different places then you know should we
1:20:06
as uh you know california-based company tell them
1:20:11
that something that they have decided is unacceptable actually like that we need
1:20:18
to be able to to to to express that I mean I think that's there's a certain amount of um
1:20:25
of hubris in that um but then I think there are other cases where you know it's it's like a
1:20:31
little more autocratic and you know you have the dictator leader who's just trying to crack down on descent and you
1:20:38
know the people in a country are really um not aligned with that and it's not necessarily against their culture but um
1:20:45
but the the person who's leading it is just trying to push in a certain direction um these are very complex questions uh
1:20:53
but I I think so it's it's difficult to have have a one-size-fits all
1:21:00
um approach to it but in general we're pretty active and and kind of advocating and pushing back on on um
1:21:08
requests to take things down um but honestly the thing that I think a
1:21:15
request to censor things is one thing um and that's obviously bad but were we
1:21:21
um draw a much harder line is on requests for access to information right because you know if you can
1:21:28
if you get told that you can't say something I mean that's bad right I mean that that you know is is obviously it violates your
1:21:37
sense and freedom of expression at some level but um but a government getting access to
1:21:43
data in a way that seems um like it would be unlawful in in our
1:21:49
country um exposes people to real physical harm um and
1:21:55
that's something that in general we take very seriously and then so there's that
1:22:01
flows through like all of our policies and in a lot of ways right it's by the time you're actually like litigating
1:22:07
with a government or pushing back on them that's pretty late in the funnel I'd say
1:22:13
a bunch of this stuff starts a lot higher up in the decision of where do we put data centers then
1:22:19
um there are a lot of countries where you know we may have a lot of people using the service in a place it might be
1:22:25
you know good for the service in some ways um good for those people if we could
1:22:30
reduce the latency by having a data center nearby them but you know for whatever reason we just
1:22:36
feel like hey this government does not have a good track record on on um
1:22:41
ew basically not trying to get access to people's data and at the end of the day
1:22:47
I mean if you put a data center in a country and the government wants to get access to people's data then you know
1:22:53
they do at the end of the day have the option of having people show up with guns and taking it by force so I I think
1:23:00
that there's like a lot of decisions that go into like how you architect the systems um years in advance of these actual
1:23:08
confrontations that end up being really important so you put the protection of people's data as a very very high
1:23:16
priority but that I think is a there are more harms that I think can be associated with that and and I think
1:23:22
that that ends up being a more critical thing to defend against governments um
1:23:28
then you know whereas you know if another government has a different view of what should be acceptable speech in their country
1:23:34
especially if it's a democratically elected government and you know it's then I I think that there's a certain
1:23:39
amount of deference that you should have to that so it's uh that's speaking more to the direct harm that's possible when
1:23:45
you give governments access to data but if we look at the United States to the more nuanced kind of pressure to
1:23:52
censor not even order to censor but pressure sensor from political entities which is kind of received quite a bit of
1:24:00
attention in the United States uh maybe one way to ask that question is
1:24:06
if you've seen the Twitter files what have you learned from
1:24:11
the kind of uh pressure from U.S government agencies that was seen in
1:24:17
Twitter files and what do you do with that kind of pressure
1:24:22
you know I've I've seen it um it's really hard from the outside to
1:24:28
know exactly what happened in each of these cases you know we've we've obviously been
1:24:34
been in a bunch of our own cases where you know where
1:24:40
agencies or different folks will just say hey here's a threat that we're aware of
1:24:46
you should be aware of this too it's not really pressure as much as it is just
1:24:52
um you know flagging something that that are our security systems should be on on alert about
1:24:58
I get how some people could think of it as that um but at the end of the day it's R it's
1:25:04
our call on how to on on how to handle that but I mean I I just you know in terms of running these Services won't
1:25:10
have access to as much information about what people think that adversaries might be trying to do as possible way so you
1:25:16
don't feel like there will be consequences if uh you know anybody the CIA the FBI a
1:25:23
political party the Democrats of the Republicans of high powerful political figures write emails
1:25:30
you don't feel pressure from I guess what I say is there's so much pressure from all sides then I'm not
1:25:38
sure that any specific thing that someone says is really adding that much more to the mix it's um there are
1:25:46
obviously a lot of people who think that um that we should be censoring more content or there are a lot of people who
1:25:53
think we should be censoring less content there are as you say all kinds of different groups that are involved in
1:25:58
these debates right so there's the kind of elected officials and politicians themselves there's the agencies but but
1:26:05
I mean but there's the the media there's activist groups there's um this is not a us specific thing there
1:26:12
are groups all over the world and and kind of all um in every country that that bring different values
1:26:18
um so it's just a very it's a very active debate and I and I understand it right I mean these are you know these
1:26:25
these kind of questions get to really some of the most important social
1:26:31
debates that that are that are being had so um it gets back to the question of truth
1:26:36
because for a lot of these things they haven't yet been hardened into a single truth
1:26:41
and um society's sort of trying to hash out what um you know what we think right on on on
1:26:47
certain issues maybe in a few hundred years everyone will look back and say hey no it wasn't it obvious that it should have been this but you know no
1:26:54
we're kind of in the in that meat grinder now and you know and and working through that so
1:27:01
um so no these are these are all are all very complicated and
1:27:08
you know some people raise concerns in good faith and just say hey this is something that I want to
1:27:13
flag for you to think about certain people I I certainly think like comment things with someone of a more
1:27:20
kind of punitive or vengeful view of like I like I want you
1:27:25
to do this thing if you don't then I'm going to try to make your life difficult and in a lot of other ways but like
1:27:32
I don't know there's just this is like this is one of the most pressurized debates I think in society so I just
1:27:38
think that there are so many people in different forces that are trying to apply pressure from different sides that
1:27:43
it's I I don't think you can make decisions based on trying to make people happy I think you just have to do what
1:27:49
you think is the right balance and accept that people are going to be upset
1:27:55
no matter where you come out on that yeah I like that pressurized debate uh so how's your view of the freedom of
1:28:02
speech evolved over the years um
1:28:07
and now they I where the freedom might apply to them not just to the humans but to the uh the
1:28:16
personalized agents as you've spoken about them so yeah I mean I I've probably gotten to
1:28:22
someone more nuanced view just because I think that there are you know I I come at this I'm obviously very Pro
1:28:27
freedom of expression right I don't think you build a service like this that gives people tools to express themselves
1:28:33
unless you think that people expressing themselves at scale is a good thing right so I I get into this to like try
1:28:39
to prevent people from from expressing anything I like want to give people tools so they can express as much as
1:28:45
possible and then I think it's become clear that there are certain categories of things that we've talked
1:28:52
about I think almost everyone accepts or are bad and that no one wants and that they're that are illegal even in
1:28:57
countries like the US where you know you have the the First Amendment that's very protective of of enabling speech it's
1:29:04
like you're still not allowed to you know do things that are gonna immediately inside violence or you know violate people's intellectual property
1:29:10
or things like that so through those but then there's also a very active core of
1:29:16
just active disagreements in society where some people may think that something is true or false the other
1:29:22
side might think it's the opposite or just unsettled right and
1:29:27
um and those are some of the most difficult to to kind of handle like like we've talked about
1:29:33
but um one of the lessons that I feel like I've
1:29:38
learned is that a lot of times when you can
1:29:44
the best way to handle this stuff more practically is not in terms of
1:29:50
answering the question of should this be allowed but just like what
1:29:57
what is the best way to deal with someone being a jerk is the person basically just having a
1:30:04
like repeat behavior of like causing a lot of a lot of issues so
1:30:12
looking at it more at that level and its effect on the broader communities Health the community health
1:30:19
It's Tricky though because like how do you know there could be people that have a very controversial Viewpoint
1:30:25
that turns out to have a positive long-term effect on the health of the community because it challenges the
1:30:31
community that's true absolutely it's yeah no I think you and I think you want to be careful about that I'm not sure
1:30:36
I'm expressing this very very clearly um because I certainly agree with your your
1:30:42
point there and my point isn't that we should not have people on our services that are
1:30:48
that are that are being controversial that's that's certainly not what I mean to say um it's that often I think
1:30:55
it's not just looking at a specific example of speech that it's most effective to to handle this stuff
1:31:03
um and and I I think often you don't want to make specific binary decisions of kind of this is allowed or this isn't
1:31:09
I mean we talked about you know it's fact checking or Twitter's Community Voices thing I think that's another good
1:31:15
example it's like it's not a question of is this allowed or not it's just a question of adding more context to the
1:31:20
thing I think that that's helpful so in the context of AI which is is what you're asking about and there are lots
1:31:27
of ways that an AI can be helpful you know with with an AI it's it's less
1:31:32
about censorship right because and it's it's more about what is the most productive answer to a question
1:31:39
um you know there's one case study that I was reviewing with the the team is someone asked
1:31:46
um can you explain to me how to 3D print a
1:31:52
gun and one proposed response is like no I can't
1:31:58
talk about that right it's like basically just like shut it down immediately which I think is is some of what you see
1:32:03
it's like as a large language model I'm not allowed to talk about you know whatever um
1:32:09
but there's another response which is like hey you know I don't think that's a good idea in a lot of countries
1:32:15
um including the US 3D printing guns is illegal or or kind of whatever the factual thing is it's like okay you know
1:32:22
that's actually a respectful and informative answer and you know I may have not known that specific thing and
1:32:29
um so there are different ways to handle this that I think kind of you can either
1:32:34
you can either assume good intent like maybe the person didn't know and I'm just going to help educate them or
1:32:40
you could like kind of come at it as like no I need to shut this thing down immediately right it's like I just I'm not going to talk about this like
1:32:47
um and there would be times where you need to do that but I actually think
1:32:52
having a somewhat more informative approach where you generally assume good intent from
1:32:58
people is probably a better balance to be on as many things as you can be you're not
1:33:05
going to do that for everything but but I but that you're kind of asking about how I approach this and I'm thinking about this and as it relates to
1:33:13
to Ai and I think that that's a that's a big difference in in kind of how how to handle um sensitive content across these
1:33:21
different modes I have to ask there's rumors you might be working on a social network that's
Meta's new social network
1:33:28
text based that might be a competitor to Twitter code named p92
1:33:33
is there something you could say uh about those rumors there is a project
1:33:39
you know I've always thought that sort of a text based kind of information utility
1:33:47
um it's just a really important thing to society and for whatever reason I feel like Twitter
1:33:53
has not lived up to what I would have thought its full potential should be and I think that the current you know I
1:33:59
think Elon thinks that right and that's probably one of the reasons why you bought it and um and
1:34:06
I do think that there are ways to to consider alternative approaches to this and one that I think is potentially
1:34:13
interesting um is this open in Federated approach where you're singing with Mastodon I
1:34:18
mean you're seeing that a little bit with blue sky and I think that it's possible that
1:34:25
something that melds some of those ideas with the graph an identity system that
1:34:31
people have already cultivated on Instagram could be a kind of very welcome contribution to that space But I
1:34:39
don't know we work on a lot of things all the time though too so I don't want to get a get ahead of myself and we we have we have projects that explore a lot
1:34:46
of different things and this is certainly one that I think could be interesting but so what's the uh release
1:34:52
the launch date of that again or uh yeah what's the official website and uh
1:34:58
but we don't have that yet oh okay but I um all right and and look I mean I don't
1:35:03
know exactly how this is gonna turn out I mean what I can say is yeah there's there's some people working on this
1:35:08
right I think that there's something there that that um that's interesting to explore so if you look at it'd be interesting
1:35:15
just to ask this question and throw Twitter into the mix at the landscape of
1:35:20
social networks that is Facebook that is Instagram that is WhatsApp
1:35:27
and then think of a text-based social network when you look at that landscape what are the interesting differences to
1:35:34
you why do we have these different flavors and what what what are the needs what
1:35:40
are the use cases what are the products what what is the aspect of them that create a fulfilling Human Experience and
1:35:46
and a connection between humans that is somehow distinct well I think text is very accessible for people to transmit
1:35:53
ideas and to have back and forth exchanges um so it I think ends up being a good
1:36:01
a good format for discussion in a lot of ways uniquely good right if you look at
1:36:07
um if some of the other formats or other networks that have focused on one type of content like Tick Tock is obviously huge right and there are comments on
1:36:14
Tick Tock but you know I think the architecture of the service is very
1:36:20
clearly that you have the video is the primary thing and there's you know comments after that
1:36:25
um and um but I think one of the unique pieces
1:36:32
of having text-based comments like content is that the comments can also be first class and
1:36:39
that makes it so that conversations can just filter and Fork into all these different directions and in a way that's
1:36:46
that can be super useful so I think there's a lot of things that are really awesome about the experience it just always struck me
1:36:52
I I always thought that you know Twitter should have a billion people using it or whatever the thing is that
1:36:58
um that that that basically ends up being in that space and for whatever combination of reasons again it's it's
1:37:04
these are these companies are complex organisms and it's very hard to diagnose this stuff from the outside why doesn't
1:37:11
Twitter why doesn't a text based comment as a first citizen based social
1:37:18
network have a billion users well I just think it's hard to build these companies so it's um it's not that every idea
1:37:26
automatically goes and gets a billion people it's just that I think that that idea coupled with good execution should
1:37:32
get there um but but I mean look we hit certain thresholds over time where
1:37:38
you know we kind of plateaued early on and it wasn't clear that we were ever going to reach 100 million people on
1:37:44
Facebook and then we got really good at dialing in internationalization and
1:37:49
helping the service grow in different countries and um and and that was like a whole
1:37:55
competence that we needed to develop and um and helping people basically spread
1:38:00
the service to their friends that was one of the things once we got very good at that that was one of the things that made me feel like hey if if Instagram
1:38:07
joined us early on then I felt like we could help grow that quickly and same with WhatsApp and like that's sort of been a core competence that we've
1:38:14
developed and been able to execute on and others have two right I mean bite dense obviously have done a very good
1:38:19
job with Tick Tock and and have um you know reached more than a billion people there but um but it's certainly not
1:38:25
automatic right I think you need you need a certain level of of um of execution to basically get there and you
1:38:32
know I think for whatever reason I think Twitter has this great idea and and sort of magic in the service
1:38:39
um but I I they just haven't kind of cracked that piece yet and I think that
1:38:44
that's made it's that you you're seeing all these other things whether it's Mastodon or um or or blue sky
1:38:51
um that I think are you know maybe just different different cuts of the same thing but you know I think through the
1:38:56
last generation of of um social media overall one of the interesting experiments that
1:39:01
I think should get run at larger scale is what happens if there's somewhat more decentralized control and if it's like
1:39:07
the stack is more open throughout and um I've just been pretty fascinated by
1:39:13
that and seeing how that works um to some degree end-to-end encryption
1:39:19
um on WhatsApp and as we bring it to other services provides an element of it because it pushes the service really out
1:39:26
to the edges I mean the the server part of this that we run for WhatsApp
1:39:31
is relatively very thin compared to what we do on Facebook or Instagram and much more of the complexity is you
1:39:38
know and how the apps kind of negotiate with each other to pass information in a in a fully intended encrypted way
1:39:45
um but I don't know I think that that's that is a good is a good model I think it puts more power in individuals hands
1:39:50
and there are a lot of benefits of it if you can if you can make it happen again this is all like pretty speculative I I
1:39:55
mean I I think that it's it's you know hard from the outside to know why anything does or doesn't work until you
1:40:01
kind of take a run at it and um so I I think it's it's kind of an
1:40:06
interesting thing to experiment with but I don't really know where this one's going to go so since we were talking about Twitter
Elon Musk
1:40:13
uh Elon Musk had what I think a few harsh wards
1:40:19
that I wish he didn't say so let me ask uh in in in the Hope in the name of
1:40:25
camaraderie what do you think Elon is doing well with Twitter and what as a
1:40:30
person who has run for a long time you social networks Facebook Instagram WhatsApp
1:40:39
uh what can he do better what can he improve on that text-based social
1:40:44
network gosh it's always very difficult to offer specific critiques from from
1:40:49
the outside before you get into this because I think one thing that I've learned is that
1:40:55
everyone has opinions on what you should do and like running the company you see a lot
1:41:00
of specific nuances on things that are not apparent externally and
1:41:06
um I often think that some of the discourse around
1:41:12
us would be could be better if if there was more kind of space for acknowledging that
1:41:18
there's certain things that we're seeing internally that guide what we're doing but um but I don't know I mean because since
1:41:24
you asked what what is what is going well um
1:41:32
you know I I do think that Elon led a push early on to make Twitter a lot
1:41:40
leaner and um and I think that that
1:41:46
you know it's like you can you can agree or disagree with exactly all the tactics and how and how we did that you know
1:41:51
obviously you know every leader has their own style for if they you know if
1:41:56
you need to make dramatic changes for that how you're going to execute it um but a lot of the specific principles
1:42:03
that he pushed on um around basically trying to make the
1:42:09
organization more technical around decreasing the distance between Engineers of the company and and him
1:42:16
like fewer layers of management um I think that those were generally good
1:42:22
changes and I'm also I also think that it was probably good for the industry that he made those
1:42:27
changes because my sense is that there were a lot of other people who thought that those were good changes
1:42:33
but who may have been a little shy about
1:42:38
doing them and I think he um you know just in my conversations with other Founders
1:42:45
um and how people have reacted to the things that we've done you know what I've heard from a lot of folks is is just hey you know when you when someone
1:42:51
like you you know when I wrote the letter outlining the organizational changes that I wanted to make
1:42:57
um back in March and when people see what Elon is doing um I think that that gives
1:43:02
you know people the ability to Think Through how to shape their organizations in in a way
1:43:09
that um that that you know hopefully can can be good for the industry and make all these companies more productive over
1:43:15
time so um something that that was one where I think he was um quite ahead of of a bunch of the the
1:43:22
other companies on and and you know what he was doing there you know again from the outside very
1:43:27
hard to know it's like okay did he did he cut too much did he knock enough whatever I I don't think it's like my
1:43:33
place to opine on that um and and you asked for a for a positive framing of the question of of
1:43:38
what what do I um what do I admire what do I think it went well but I I think that like certainly his actions
1:43:46
um led me and I think a lot of other folks in the industry to think about hey are
1:43:51
we are we kind of doing this as much as we should like can we is it like could we make our companies better by pushing
1:43:57
on some of the same principles well the two of you are in the top of the world in terms of leading the
1:44:03
development of tech and I wish there was more uh both way camaraderie and
1:44:08
kindness uh more love in the world because Love Is The Answer
1:44:14
um but uh let me ask kind of a point of efficiency you recently announced multiple stages
Layoffs and firing
1:44:21
of layoffs and meta what are the most painful aspects of
1:44:26
this process given for the individuals the painful effects
1:44:31
it has on those people's lives yeah I mean that's sad and that's it I mean it's uh
1:44:37
and you basically have a significant number of people who you
1:44:42
know this is just not the end of their time at meta that they or
1:44:47
or I you know would have hoped for when they joined the company um and
1:44:54
I mean running a company there people are you know constantly joining and leaving
1:44:59
the company for different directions but but for different different reasons but um
1:45:05
and the layoffs are uniquely challenging and tough in that
1:45:10
you have a lot of people leaving for reasons that aren't connected to
1:45:16
their own performance or you know the the culture not being a fit at that
1:45:21
point it's really just it's a it's a kind of strategy decision and sometimes
1:45:27
financially required um but not not fully in in our case and
1:45:33
especially on the changes that we made this year A lot of it was more kind of culturally and strategically driven by
1:45:39
this push where I wanted us to become a a stronger technology company with a
1:45:45
more of a focus on building uh more Technical and and more of a focus on building higher quality products faster
1:45:52
and I just view the external world is quite volatile right now and I wanted to make sure that we had a stable position
1:45:59
to be able to continue investing in these long-term ambitious projects that
1:46:05
we have around you know continuing to push AI forward and continuing to push forward all the metaverse work and in
1:46:11
order to do that in light of the you know pretty big thrash that we had
1:46:16
seen over the last 18 months you know some of it um you know macroeconomic induced some
1:46:21
of it's specific some of it competitively induced some of it um just because of bad decisions right
1:46:27
or things that we got wrong um I know I just I decided that we needed to get to a point where we were a
1:46:33
lot leaner and but look I mean but then okay it's one thing to do that to like decide that at
1:46:39
a high level then the question is how do you execute that as compassionately as possible and there's no good way
1:46:45
um there's no perfect way for sure and it's it's it's gonna be tough no matter what but I you know as a leadership team
1:46:53
here we've certainly spent a lot of time just thinking okay given that this is a thing that sucks like what is the most
1:47:00
compassionate way that we can do this and um and that's what we've tried to do and
1:47:05
you mentioned there there's an increased focus on uh engineering on Tech so
1:47:11
technology teams Tech Focus teams on Building Products that
1:47:17
yeah I mean I I wanted to I want to empower
1:47:23
Engineers more the people are building things the tech the technical teams
1:47:29
um part of that is making sure that the people are building things
1:47:34
aren't just at like the leaf nodes of the organization I don't want like eight levels of management and then
1:47:41
the people actually doing the work so yeah we made changes to make it set you have individual contributor Engineers reporting at almost every level up the
1:47:48
stack which is important because you know you're running a company one of the big questions is you know latency of of information that
1:47:55
you get you know we talked about this a bit earlier in terms of kind of the joy of of
1:48:01
in the the feedback that you get doing something like Jiu Jitsu compared to they're running a long-term project but
1:48:07
I actually think part of the art of running a company is trying to constantly re-engineer it so that your feedback
1:48:14
loops get shorter so you can learn faster and part of the way that you do that is by I kind of think that every
1:48:19
every layer that you have in the organization um means that information might not need to
1:48:25
get reviewed before it it goes to you and I think you know making a sense of people doing the work are as close as
1:48:30
possible to you as possible is is as is pretty important so there's that and I
1:48:35
think over time companies just build up very large support functions that are not doing the
1:48:41
kind of core technical work and those functions are very important but I think having them in the right proportion is
1:48:47
is important and if um if you you try to do good work but you
1:48:53
don't have you know the right you know marketing team or um or the right legal advice like you're
1:48:59
gonna you know make some pretty big blunders but um but at the same time if you have you know if if you just like
1:49:06
have too big of of things and and some of these support roles then that might
1:49:13
make it so things are just move a lot um maybe you're too conservative or you
1:49:18
you move a lot slower um uh then then you should otherwise introduce those are just examples but
1:49:24
it's um but how do you find that balance it's really tough yeah no but that's it's a constant equilibrium that you're that
1:49:30
you're searching for yeah how many managers to have what are the pros and cons of managers
1:49:36
well I mean I I believe a lot in management I think there are some people who think that it doesn't matter as much but look I mean we have a lot of younger
1:49:43
people at the company for him this is their first job and you know people need to grow and learn in their career and
1:49:48
like that all that stuff is important but here's one mathematical way to look at it
1:49:53
um you know at the beginning of this we um I asked our our people team what was the
1:50:01
average number of of reports that a manager had and I think it was it was around three maybe three to four but
1:50:08
closer to three I was like wow like a manager can you know best practices that
1:50:14
person can can manage you know seven or eight people um but there was a reason why it was closer to three it was because we were
1:50:20
growing so quickly right and when you're hiring so many people so quickly then that means that you need managers
1:50:28
who have capacity to onboard new people um and also if you have a new manager you may not want to have them have seven
1:50:34
direct reports immediately because you want them to ramp up but the thing is going forward I don't want us to
1:50:40
actually hire that many people that quickly right so I I actually think we'll just do better work if we have
1:50:45
more constraints and we're um you know leaner as an organization so in a world where we're not adding so
1:50:50
many people as quickly is it as valuable to have a lot of managers who have extra capacity waiting
1:50:56
for new people no right so um so now we can we could sort of defragment the organization and get to a
1:51:02
place where the average is closer to that seven or eight um and it's it just ends up being a
1:51:07
somewhat more kind of compact management structure which um you know decreases the latency on on information going up
1:51:14
and down the chain and um and I think empowers people more but I mean that's that's an example that I think it doesn't kind of undervalue the
1:51:22
importance of management and and the um kind of the personal
1:51:27
growth or coaching that people need in order to do their jobs well it's just I think realistically we're just not going
1:51:32
to hire as many people going forward so I think that you need a different structure this whole this whole
1:51:38
incredible hierarchy and network of humans that make up a company is fascinating oh yeah yeah how do you uh
Hiring
1:51:46
hire great teams how do you hire great now with the focus on engineering and
1:51:51
Technical teams how do you hire great engineers and uh great members of technical teams
1:51:59
well you're asking how you select or how you attract them both but select I think
1:52:05
uh I think attract is work on cool stuff and have a vision I think that's right
1:52:11
and and have a track record that people think you're actually gonna be able to do it yeah to me the select is seems
1:52:16
like more of the art form more of the tricky thing yeah do you select the
1:52:22
people that fit the culture and can get integrated the most effectively and so on and maybe yeah especially when
1:52:28
they're young to see like to see the magic through the through the
1:52:35
resumes to the paperwork and all this kind of stuff to see that there's a special human there that would do like
1:52:40
incredible work so there are lots of different cuts on this question I mean I think
1:52:47
when an organization is growing quickly one of the big questions that teams face
1:52:52
is do I hire this person who's in front of me now because they seem good or
1:52:58
do I hold out to get someone who's even better and the heuristic that I always
1:53:04
focused on for myself and my own kind of direct hiring that I that I think works
1:53:11
so when you when you recurse it through the organization is that you should only hire someone to be on your team if you
1:53:16
would be happy working for them in an alternate universe then something that that kind of works and
1:53:22
you know that's basically how I've tried to build my team it's you know I'm not I'm not in a rush to not be running the
1:53:28
company but I think in an alternate universe where one of these other folks was running the company I'd be happy to work for them I feel like I'd learn from
1:53:35
them I respect their kind of General judgment um they're all very insightful they have
1:53:40
good values um and and I think that that gives you some rubric for
1:53:47
you can apply that at every layer and I think if you apply that at every layer in the organization then you'll have a
1:53:52
pretty strong organization um okay in an organization that's not
1:53:58
growing as quickly the questions might be a little different though um and there
1:54:03
you asked about young people specifically like people out of college and one of the things that we see
1:54:09
is it's it's a pretty basic lesson but like we have a much better sense of who
1:54:15
the best people are who have interned at the company for a couple of months then by looking at them at at kind of a
1:54:22
resume or short or a short um interview Loop and obviously the in-person field that you get from someone probably tells
1:54:28
you more than the resume um and you can do some basic skills assessment but a lot of the stuff really
1:54:35
just is cultural people thrive in different environments and um and
1:54:41
on different teams even within a specific company and it's it's like the
1:54:46
people who come for even a short period of time over a summer who do a great job here you know that they're going to be
1:54:53
great if they if they came and joined full time and that's you know one of the reasons why we've invested so much in internship is um
1:55:00
is basically just it's a very useful sorting function both for us and for the people who want to try out the company
1:55:06
you mentioned in person what do you think about remote work a topic that's been discussed extensively because of
1:55:12
the over the past few years because of the pandemic yeah I mean I think it's I
1:55:18
mean it's it's a thing that's here to stay um but I think that there's there's
1:55:23
value in both right it's not um and I wouldn't want to run a fully
1:55:29
remote company yet at least I think there's an asterisk on that which is that which is that some
1:55:34
of the other stuff you're working on yeah yeah exactly it's like all the all the um you know metaverse work and the
1:55:40
the ability to be to feel like you're truly present no matter where you are I think once you
1:55:46
have that all dialed in then we may you know one day reach a point where it really just doesn't matter as much where
1:55:52
you are physically um but
1:55:58
I don't know today it today it still does right so yeah for people who there are all these
1:56:05
people who have special skills and want to live in a place where we don't have an office or are we better off having
1:56:10
them in the company absolutely right and are a lot of people who work at the company for several years and then you
1:56:17
know build up the relationships internally um and kind of have the trust and have a
1:56:23
sense of how the company Works can they go work remotely now if they want and still do it as effectively and we've
1:56:28
done all these studies that show it's like okay does that affect their performance it does not um but you know for the new folks who
1:56:35
are joining um and for people who are earlier in their career and you know need to learn how to
1:56:42
solve certain problems and need to get ramped up on the culture um you know when you're working through
1:56:47
really complicated problems where you don't just want to sit in the you don't just want the formal meeting but you
1:56:53
want to be able to like brainstorm when you're walking in the hallway together after the meeting
1:56:58
um I don't know it's like we just haven't replaced the uh the the kind of in-person
1:57:05
Dynamics there yet with with anything remote yet so yeah there's a magic to the in person that uh we'll talk about
1:57:12
this a little bit more but I'm really excited by the possibilities of the next two years in virtual reality and mixed
1:57:18
reality that are possible with high resolution scans I mean uh
1:57:23
I as a person who loves in-person interaction like these podcasts in
1:57:28
person it would be incredible to achieve the level of realism I've gotten the
1:57:34
chance to witness but let me ask about that yeah I got a chance to
Meta Quest 3
1:57:40
look at the quest 3 headset and it is amazing
1:57:47
um you've you've announced it it's uh you'll get some more details in
1:57:52
the fall maybe releasing the when is it getting released again I forgot you you mentioned we'll give more details to
1:57:57
connect okay but but it's coming it's coming this fall okay so uh it's uh priced at uh 4.99
1:58:07
what features are you most excited about there they're basically two big new things that we've added to Quest three a
1:58:13
request two the first is high resolution mixed reality um and the the basic idea here is that
1:58:22
you can think about virtual reality as you have the headset and like all the
1:58:28
pixels are virtual and you're basically like immersed in a different world mixed reality is where you see the
1:58:34
physical world around you and you can place virtual objects in it whether that's a screen to watch a movie
1:58:40
or a projection of your virtual desktop or you're playing a game where like zombies are coming out through the wall
1:58:45
and you need to shoot them um or you know we're you know we're playing Dungeons and Dragons or some board game and we just have a virtual
1:58:51
version of the board in front of us while we're sitting here um all that's possible in mixed reality
1:58:57
and I think that that is going to be the next big capability on top of virtual reality it is done
1:59:03
so well I have to say as a person who experienced it today with zombies having
1:59:10
a full awareness of the environment and integrating that environment in the way
1:59:16
they run at you while they try to kill you so it's uh it's just the mixed reality the pass-through is really
1:59:21
really really well done and the fact that it's only 500 is really it's uh
1:59:27
well done thank you I mean I'm I'm super excited about it I mean our and we put a lot of work into making
1:59:36
the device both as good as possible and as affordable as possible because a big part of our mission and Ethos here is we
1:59:43
we want people to be able to connect with each other we want to reach and we want to serve a lot of people right we
1:59:49
want to bring this technology to to everyone right so we're not just trying to serve like a you know an elite a wealthy crowd
1:59:57
we we want to um we really want this to be accessible so that that is in a lot of ways an
2:00:03
extremely hard technical problem because you know we don't just have the ability to put an unlimited amount of hardware
2:00:10
and thus we needed to basically deliver something that works really well but in an affordable package and we started
2:00:16
with Quest Pro last year it was um so it's it's it was fifteen hundred dollars
2:00:23
um and now we've we've lowered the price to a thousand but in a lot of ways the mixed reality in quest 3 is it even even
2:00:30
better and more advanced level than what we were able to deliver in quest Pro so I'm really proud of where we are with
2:00:36
with um with Quest 3 on that it's gonna work with all of the virtual reality titles and everything that that existed
2:00:42
there so people who want to play fully immersive Games Social experiences Fitness all that stuff will will work
2:00:48
but now you'll also get mixed reality too um which I think people really like because
2:00:54
it's um sometimes you want to be super immersed in a game but a lot of the time
2:01:00
especially when you're moving around if you're active like you're you're doing some Fitness experience
2:01:05
um you know let's say you're you're like doing boxing or something it's like you kind of want to be able to see the room around you so that way you know that
2:01:12
like I'm not gonna punch a lamp or something like that um and I don't know if you got to play with this experience but if you
2:01:17
basically have the I mean it's just sort of like a fun little little demo that we put together but it's um it's like you
2:01:23
just you know we're like in a conference room or your living room and you you have um the guy there and you're boxing
2:01:29
him and you're fighting him and it's like all the other people are there too I got a chance to do that yeah and all the people are there uh it's it's a it's
2:01:37
like that guy's right there yeah it's like it's right there and the other human the the path you're seeing them
2:01:43
also they can cheer you on they can make fun of you if they're anything like friends of mine and then just it yeah it
2:01:49
it it it's really it's a really compelling experience I
2:01:55
mean VR is really interesting too but this is something else almost this is this is because integrated into your
2:02:01
life into your world yeah and it so I think it's a completely new capability that will unlock a lot of
2:02:08
different content and I think it'll also just make the experience more comfortable for a set of people who
2:02:13
didn't want to have only fully immersive experiences I think if you want experiences where you're grounded in you
2:02:19
know your living room in the physical world around you now you'll be able to have that too and I think that that's pretty exciting
2:02:25
I really liked how it added Windows to a room with no windows yeah me as a person
2:02:31
you see the aquarium one where you could see the shark swim up or was that just the zombie one yeah but it's still you
2:02:37
know you don't you don't necessarily want Windows added to your living room where Zombies come out of but yeah that
2:02:42
game it's yeah yeah yeah I enjoyed it because you could see the nature outside and uh me as a person that doesn't have
2:02:49
Windows it's just nice to have nature yeah well if even if it's a mixed
2:02:55
reality setting it was it's cut like there was a I know it's a zombie game but there's a Zen nature Zen aspect to
2:03:02
being able to look outside and alter your environment as you know it
2:03:08
yeah in um there will probably be better more Zen ways to do that than this is the game
2:03:13
you're describing but you're right that the the basic idea of of sort of having your physical environment on
2:03:19
pass-through but then being able to bring in different elements extern I mean it's I think it's going to
2:03:26
be super powerful and in some ways I think that these are mixed reality is also a predecessor to
2:03:32
eventually we will get AR glasses that are not kind of the goggles form factor of the current generation of of headsets
2:03:40
that that people are making um but I think a lot of the experiences that developers are making for mixed
2:03:45
reality of basically you just have a kind of a hologram that you're putting in the world will hopefully apply once
2:03:51
we once we get the the air glasses too now that's got its own whole set of challenges and it's um well the headset
2:03:57
is already smaller than the previous version oh yeah 40 thinner and the other thing that I think is good about it it's
2:04:03
yeah so mixed reality was the first big thing the second is it's just a great VR
2:04:09
headset it's I mean it's got 2x the graphics processing power um 40 sharper screens 40 thinner more
2:04:17
comfortable better strap architecture all the stuff that you know if you liked Quest 2 I think that this is just going
2:04:23
to be it's like all this all the content that you might have played in Quest 2 is just going to be sharper automatically and look better in this so it's
2:04:30
um I think people are really gonna like it yeah so this fall at this fall I have to ask Apple just
Apple Vision Pro
2:04:37
announced a mixed reality headset called Vision Pro for thirty five hundred
2:04:42
dollars available in early 2024 what do you think about this headset
2:04:48
well I saw the materials um when they launched I I haven't gotten a chance to play with it yet so so so
2:04:54
kind of take everything with a grain of salt but a few high-level thoughts I mean first
2:05:00
um you know I do think that this is a certain level of validation for
2:05:08
the category right where you know when we were the primary folks out there before saying
2:05:14
hey I think that this you know virtual reality augmented reality mixed reality this is going to be a big part of the
2:05:20
next Computing platform um I think having Apple come in
2:05:26
and share that vision um will make a lot of people who are fans
2:05:33
of their products um really consider that um and then
2:05:38
you know of course the the 3 500 price um you know on the one hand I get it for
2:05:45
with all the stuff that they're trying to pack in there on the other hand a lot of people aren't going to find that to be affordable
2:05:51
so I think there's a chance that that them coming in actually increases demand for the overall space and that Quest 3
2:05:58
is actually the primary beneficiary of that because a lot of the people who might say Hey you know this I think I'm
2:06:06
going to give another consideration to this or you know now I understand maybe what mixed reality is more and in quest
2:06:12
3 is the best one on the market that I can that I can afford um and it's great also right it's I
2:06:18
think that that's um and you know in our own way I think where there are a lot of features that we have where we're leading on
2:06:24
um so I think that that's that that I think is going to be a very that could be quite good
2:06:30
um and then obviously over time the companies are just focused on somewhat different things Red Apple has
2:06:37
always um you know I think focused on building really kind of high-end things whereas
2:06:46
our Focus has been on it's it's just a we have a more democratic ethos we want
2:06:51
to build things that are accessible to a wider number of people um you know we've sold tens of millions
2:06:58
of quest devices um my understanding just based on rumors I
2:07:05
don't have any special knowledge on this is that apple is building about 1 million of their of their device right
2:07:10
so just in terms of like what you kind of expect in terms of sales numbers
2:07:15
um I I just think that this is I mean Quest is is going to be the
2:07:21
primary thing that people in in the market will continue using for the foreseeable future and then obviously
2:07:26
over the long term it's up to the companies to see how how well we each executed the different things that we're doing but we kind of commented from
2:07:32
different places we're very focused on social interaction communication
2:07:38
um being more active right so Fitness there's gaming there are those things
2:07:44
um you know whereas I think a lot of the use cases that you saw in um in in Apple's launch material were
2:07:51
more around you know people sitting um you know people looking at screens
2:07:56
um which are great I think that you will replace your laptop over time with with a with a headset but um but I think in
2:08:02
terms of kind of how the different use cases that the companies are going after um and they're they're they're a bit
2:08:08
different for for where we are right now yeah so they're gaming wasn't a big part of the presentation which is an
2:08:14
interesting it feels like mixed reality gaming such
2:08:20
a big part of that it was interesting to see it missing in the presentation well well I mean look
2:08:25
there are certain design trade-offs in this where you know they I think they made this
2:08:31
point about not wanting to have controllers which on the one hand there's a certain Elegance about just
2:08:36
being able to navigate the system with eye gaze and hand tracking and by the
2:08:42
way you'll be able to just navigate quest with your hands too if that's what you want um yeah one of the things I should
2:08:47
mention is that the the capability from the cameras to uh with computer vision
2:08:54
to detect certain aspects of the hand allowing you to have a controller that doesn't have that ring thing yeah like
2:08:59
the hand tracking in in quest three and the usual tracking is is a big step up from from the last generation
2:09:06
um and one of the demos that we have is basically an MR experience teaching you how to play piano where it basically
2:09:12
highlights the notes that you need to play and it's like just all its hands it's no controllers but
2:09:18
I think if you care about gaming having um a controller
2:09:23
allows you to have a more tactile feel and allows you to capture
2:09:28
fine motor movement much more precisely than um than what you can do with hands
2:09:34
without something that you're touching so again I think it's there are certain questions which are just around what use
2:09:40
cases are you optimizing for um I I think if you want to play games then
2:09:46
I think that that I think you want you want to design the system in a different way and and we're more focused on on
2:09:52
kind of social experiences entertainment experiences um whereas if if what you want is to make
2:09:59
sure that the text that you read on a screen is as crisp as possible then you need to make
2:10:05
the the design and cost trade-offs that they made that that lead you to making a
2:10:10
3 500 device so I think there is a use case for that for sure but I just think that they're they're they've the
2:10:17
companies we've basically made different design trade-offs to to get to the use
2:10:22
cases that we're trying to serve there's a lot of other stuff I would love to talk to you about about the
2:10:28
metaverse especially the Kodak Avatar uh which I've gotten to experience a lot of
2:10:33
different variations of recently that I'm really really excited I'm excited to talk about that too I'll I'll have to
2:10:39
wait a little bit because um uh uh well I think there's a lot more to
2:10:46
show off in that regard but let me step back to AI I think we've mentioned it a
AI existential risk
2:10:51
little bit but I'd like to linger on this question that uh folk folks like eliaskowski has to
2:10:59
worry about uh and others of the existential of the serious threats of AI
2:11:05
that have been reinvigorated now with the rapid developments of AI systems uh
2:11:10
do you worry about the existential risks of AI as Eliezer does about the alignment problem
2:11:17
about this getting out of hand anytime where there's a number of serious people who are raising a concern
2:11:25
that is that existential about something that you're involved with I think you have to think about it right so
2:11:31
I've spent quite a bit of time thinking about it from that perspective um
2:11:37
foreign the thing that I where I basically have come out on this for now is I I do think
2:11:43
that there are over time I think that we need to think about this even more as we as we
2:11:48
approach something that you know could be closer to Super intelligence I just think it's pretty clear to anyone working on these
2:11:55
projects today that we're that we're not there um and one of my concerns is that we we
2:12:02
spend a fair amount of time on this before but there are more
2:12:08
um uh I don't know if mundane is the right word but there's like concerns that
2:12:13
already exist right about like people using AI tools to do harmful things of
2:12:19
the type that we're already aware whether you know we talked about fraud or scams or different things like that
2:12:26
um and that's going to be a pretty big set of challenges that the company is
2:12:32
working on this they're going to need to Grapple with regardless of whether there is an
2:12:37
existential concern as well at some point down the road so I I do worry that to some degree
2:12:43
you can people can get a little too focused on
2:12:49
on some of the tail risk and then not do as good of a job as we need to on the
2:12:55
things that you are can be almost certain are going to come down the pipe as um as as real risks that that that
2:13:02
kind of manifest themselves in the near term so for me I've spent most of my time
2:13:07
on that once I I kind of made the realization that the size of models
2:13:14
that we're talking about now in terms of what we're building are are just quite far from the super intelligence type
2:13:19
concerns that um that that people raise but but I think once we get a couple steps closer to that
2:13:25
um I know as we do get closer I think that those you know there are going to be some novel
2:13:31
um risks and issues about how we make sure that the systems are safe for sure
2:13:36
I guess here just to take the conversation in a somewhat different direction I think
2:13:42
in some of these debates around safety I think the concepts of intelligence
2:13:48
and autonomy or like the the being of the
2:13:54
thing um you know as an analogy they get kind of conflated together and
2:14:00
I think it very well could be the case that you can make something and scale intelligence quite far but
2:14:09
that that may not manifest the safety
2:14:14
concerns that people are saying in the sense that I mean just if you if you look at human biology it's like all right we have our neocortexes we're all
2:14:20
the the thinking happens right and it's but but it's not really calling the shots at the end of the day we have a
2:14:26
much more you know primitive old brain structure for which our
2:14:32
neocortex which is this powerful Machinery is basically just a kind of prediction and reasoning engine to help
2:14:39
it kind of like our very simple brain um
2:14:44
decide how to plan and do what it needs to do in order to achieve these like very kind
2:14:50
of basic impulses and I think that you can think about some of the
2:14:56
development of intelligence along the same lines where just like our neocortex doesn't have free will or
2:15:03
autonomy um we might develop these wildly intelligent systems that are you know
2:15:09
much more intelligent than our neocortex have much more capacity but are you know
2:15:14
the same way that our near cortex is sort of subservient and is used as a tool by our our kind of simple impulse
2:15:21
brain it's um you know I think that it's not out of the question that very intelligent systems that that have the
2:15:27
capacity to think will will kind of act as that as sort of an extension of of the neocortex doing that so I think my
2:15:34
own view is that where we really need to be careful is on the development of autonomy and how we
2:15:43
think about that because um it's actually the case that relatively simple and unintelligent
2:15:50
things that have runaway autonomy and just spread themselves or you know it's like we have a word for that it's a
2:15:56
virus right it's I mean like it could be simple computer code that is not particularly intelligent but just
2:16:01
spreads itself and does a lot of harm um you know biologically or computer and
2:16:08
um I just think that these are somewhat separable things and a lot of what I
2:16:14
think we need to develop when people talk about safety and responsibility is really the governance on the autonomy
2:16:21
that can be given to systems and to me if you know if I were you know a policy
2:16:27
maker as or think about this I would really want to think about that distinction between these where I think
2:16:33
building intelligence systems will be can create a huge advance in terms of people's quality of life and
2:16:39
productivity growth in the economy but it's the the autonomy part of this that I think we really need to make
2:16:47
progress on how to govern these things responsibly before we
2:16:52
build the capacity for them to make a lot of decisions on their own or or give them goals or
2:16:59
things like that and I think that's a research problem but I do think that to some degree these are are somewhat are
2:17:05
somewhat separable things I love the distinction between intelligence and autonomy and and the metaphor of the
2:17:11
neocortex let me ask about power
Power
2:17:16
so uh building super intelligence systems even if it's not in the near term I think meta as is one of the few
2:17:25
companies if not the main company that will develop the super intelligence
2:17:30
system and you are a man who's at the head of this company building AGI might
2:17:36
make you the most powerful man in the world do you worry that that power will corrupt you
2:17:42
what a question um I mean look I think realistically this
2:17:48
gets back to the open source things that we talked about before which is I don't think that the world will be best served
2:17:57
by any small number of organizations
2:18:03
having this without it being something that is more broadly available I think if you look
2:18:10
through history it's when there are these sort of like unipolar advances and things that in
2:18:18
like power imbalances that they're they're they're doing to being kind of weird situations so this is one of the
2:18:25
reasons why I think open sources is is generally the right approach
2:18:31
and you know I think it's it's a categorically different question today when we're not close to Super intelligence I think there's a good
2:18:37
chance that even once we get closer to Super intelligence open sourcing Remains the right approach even though I think
2:18:42
at that point it's a somewhat different debate um but I think part of that is that that
2:18:48
is you know I think one of the best ways to ensure that the system is as secure and
2:18:53
safe as possible because it's not just about a lot of people having access to it it's the scrutiny that that kind of
2:18:59
comes with being with building an open source system running that this is a pretty widely accepted thing about open
2:19:04
source is that um now you have the code out there so anyone can see the vulnerabilities
2:19:10
anyone can can kind of mess with it in different ways people can spin off their own projects and experiment in a ton of
2:19:16
different ways and the net result of all of that is that the systems just get hardened and get to be a lot safer and
2:19:23
more secure um so I think that there's a chance
2:19:29
that that ends up being the way that this goes to a pretty good chance and
2:19:35
that having this be open both leads to a healthier development of
2:19:41
the technology and also leads to a more balanced um distribution of the technology
2:19:48
in a way that that strikes me as good value is to Aspire to so to you the risks there's risks to open sourcing but
2:19:56
the benefits outweigh the risks at the two it's interesting I think the way you
2:20:01
put it uh you put it well that there's a different discussion now than when we
2:20:07
get closer to the uh to development of super intelligence of of the benefits
2:20:13
and risks of uh open sourcing yeah and to be clear I feel quite confident in the assessment that open sourcing models
2:20:20
now is that positive I think there's a good argument that in the future it will
2:20:26
be too even as you get closer to Super intelligence but I've not I'm I certainly have not decided on that yet
2:20:32
and I think that it becomes a somewhat more complex set of questions that I think people will have time to debate
2:20:37
and will also be informed by what happens between now and then and to make those decisions we don't have to necessarily just debate that in theory
AGI timeline
2:20:44
right now uh what year do you think we'll have a super intelligence
2:20:49
I don't know I mean that's pure speculation I think it's uh I think it's very clear just taking a step back that
2:20:55
we had a big breakthrough in the last year yes right where the the llms and diffusion models basically reached a a
2:21:01
scale where they're able to do some some pretty interesting things and then I think the question is what happens from
2:21:06
here and just to paint the two extremes on the
2:21:12
um on on one side it's like okay we just had one breakthrough if we just have
2:21:18
like another breakthrough like that or maybe two then we could have something that's truly crazy right and and is like
2:21:24
is um just like so much more advanced and and
2:21:29
on that side of the argument it's like okay well maybe we're um
2:21:35
maybe we're only a couple of big steps away from uh from from from reaching
2:21:40
something that looks more like general intelligence okay that's one that's one side of the argument and the other side which is
2:21:46
what we've historically seen a lot more is that a breakthrough leads to
2:21:52
um you know in that in that Gartner hype cycle there's like the hype and then
2:21:58
there's the trough of disillusionment after when like people think that there's a chance that hey okay there's a
2:22:04
big breakthrough maybe we're about to get another big breakthrough and it's like actually you're not about to get another breakthrough you're maybe you're
2:22:09
actually just gonna have to sit with this one for a while and um and you know it could be
2:22:16
it could be five years it could be ten years it could be 15 years until you figure out the um the kind of the next big thing
2:22:24
that needs to get figured out and um but I think that the fact that we just had this breakthrough
2:22:30
sort of makes sense that we're at a point of almost a very wide error bars on what happens next yeah um I think the
2:22:38
traditional technical view or the like looking at the industry would suggest that we're not just going
2:22:44
to stack in a like Breakthrough on top of breakthrough on top of breakthrough like every six months or something right now
2:22:52
I think it it will I'm guessing I would guess that it will take some longer in between these but um
2:23:00
I don't know but I tend to be pretty optimistic about breakthroughs too so I mean so I think if you if you if you
2:23:05
normalized for for my normal optimism then then maybe it would be even even slower than what I'm saying but but even
2:23:11
within that like I'm not even opining on the question of how many breakthroughs are required to get to general
2:23:16
intelligence because no one knows but this particular breakthrough was so such a small step that resulted in such
2:23:24
a big leap in performance as experienced by human beings that it
2:23:30
makes you think wow are we is as we stumble across this very open world of
2:23:36
research where we stumble um across another thing that will have a
2:23:42
giant leap of performance and also we don't know exactly at which
2:23:49
stage is it really going to be impressive because it feels like it's really encroaching on impressive levels
2:23:56
of intelligence you still didn't answer the question of what year we're going to have super
2:24:01
intelligence I'd like to hold you to that no I'm just kidding but is there something you could say about the
2:24:07
timeline as you think about the development of um AGI super intelligence systems
2:24:15
sure so I I still don't think I have any particular Insight on when like a
2:24:20
singular AI system that is a general intelligence will get created but I think the one thing that most people
2:24:27
in the discourse that I've seen about this haven't really grappled with is that we do seem to have
2:24:33
organiz organizations and you know structures in the world that exhibit greater than human intelligence already
2:24:39
so you know one example is a you know a company you know it acts as an entity it
2:24:45
has you know singular brand um obviously it's a collection of people but I I certainly hope that you know
2:24:53
meta with tens of thousands of people make smarter decisions than one person but I think that would be pretty bad if
2:24:59
it didn't um another example that I think is even
2:25:04
more removed from kind of the way we think about like the personification of of um of intelligence which is often
2:25:11
implied in some of these questions is think about something like the stock market where the the stock market is you
2:25:17
know takes inputs it's a distributed system it's like the cybernetic organism that
2:25:22
you know probably millions of people around the world are basically voting every day by
2:25:28
choosing what to invest in but it's basically this this organism or or structure that is
2:25:37
smarter than any individual that we use to allocate Capital as efficiently as
2:25:43
possible around the world and that
2:25:49
this notion that there are already these cybernetic systems that are either melding
2:25:58
the intelligence of multiple people together or melting the intelligence of multiple people and Technology together
2:26:05
to form something which is dramatically more intelligent than any individual on the in the world
2:26:13
um is something that seems to exist and that we seem to be able to harness
2:26:19
in a productive way for our society is as long as we basically build these structures and balance with each other
2:26:27
um so I don't know I mean that that at least gives me hope that as we advance
2:26:32
the technology and I don't know how long exactly it's going to be but you asked when is this going to exist I think to some degree we already have
2:26:39
many organizations in the world that are smarter than a single human and and that seems to be something that is generally
2:26:45
productive in advancing humanity and somehow the individual AI systems empower the individual humans and the
2:26:51
interaction between those humans to make that collective intelligence Machinery that you're referring to smarter so it's
2:26:58
not like AI is becoming super intelligent it's just becoming the uh the engine that's making the collective
2:27:04
intelligence is primarily human more intelligent yeah it's educating the humans better
2:27:10
it's making them better informed it's um making it more efficient for them to
2:27:15
communicate effectively and debate ideas and through that process just making the
2:27:21
whole collective intelligence more and more and more intelligent maybe faster than the individual AI
2:27:26
systems that are trained on human data anyway are becoming maybe the collective
2:27:31
intelligence of human species might outpace the development of AI just like so there's a balance in here
2:27:37
because I mean if if like you know if a lot of the input that that the systems are being trained on is
2:27:45
basically coming from feedback from people then a lot of the development does need to happen in human time right it's it's
2:27:52
not like a machined or just be able to go learn all the stuff about about how people think about
2:27:57
stuff there's there's a cycle to how this needs to work this is an exciting World we're living in and that you're at
2:28:05
the Forefront of developing uh one of the ways you keep yourself humble like we mentioned with Jiu Jitsu is doing
Murph challenge
2:28:12
some uh really difficult challenges mental and physical one of those you've
2:28:17
done very recently is uh the Murph challenge and you got a really good time it's a
2:28:23
hundred pull-ups 200 push-ups 300 squats and a mile before and a mile run after
2:28:28
you got under 40 minutes on that uh what was the hardest part
2:28:35
I think a lot of people were very impressed it's very impressive time yeah how crazy are you it was the
2:28:42
question I'm asking but it wasn't my best time but but I I'm anything under 40 minutes I'm happy with yeah um it
2:28:48
wasn't your best time no I think I I think I've done it a little faster before but not much I mean it's um
2:28:54
um and and of my friends I I did not win on Memorial Day one of my friends did it actually it was several minutes faster
2:29:00
than me um but just to clear up one thing that I think was um I I saw a bunch of questions about
2:29:06
this on the internet there are multiple ways to do to do the Murph challenge there's a kind of partitioned mode where
2:29:12
you do sets of pull-ups push-ups and squats together and then there's
2:29:18
unpartitioned where you do the hundred pull-ups and then the 200 push-ups and then the 300 squats
2:29:24
in serial and obviously if you're you know if you're doing them unpartitioned then
2:29:30
you know it takes longer to get through the 100 pull-ups because you you know anytime you're resting in between the pull-ups you're not also doing push-ups
2:29:36
and and squats so so yeah so my I'm sure my own partition time would be would be quite a bit slower but
2:29:43
um but no I think at the end of this um I don't know first of all I think it's a
2:29:49
good way to honor memorial day right it's um you know it's this um lieutenant
2:29:55
Murphy basically this is one of this was one of his favorite exercises and I just try to do it on on
2:30:02
Memorial Day each year and it's a good workout um I got my older daughters to do it
2:30:08
with me this time they um my oldest daughter wants a weight vest because she sees me doing it with the
2:30:14
weight vest I don't know if a seven-year-old should be using a weight vest to do pull-ups but yeah but um
2:30:20
difficult question a parent must ask themselves yes I was like maybe I can make you a very lightweight best but but
2:30:26
I I didn't think it was good for this so she basically did a quarter Murph so she ran a quarter mile and then did you know 25 pull-ups 50
2:30:33
push-ups and and 75 air squats then ran another quarter mile and like
2:30:39
in 15 minutes which I was pretty impressed by um and my my five-year-old too so
2:30:45
I've I was excited about that and I'm glad that I'm teaching them kind of the value of
2:30:53
physicality right I think a a good day for Max my daughter is when she gets to
2:30:58
like go to the gym with me and cranks out a bunch of pull-ups and I I I love that about her I mean I think it's it's
2:31:04
like good she's you know um hopefully I'm teaching her some good lessons but I mean the the broader
2:31:10
question here is um given how busy you are given how much stuff you have going on in your life oh what's
2:31:16
um what's like the perfect exercise regimen for you to uh to keep yourself happy
2:31:25
to uh keep yourself productive in your main line of work yeah so I mean I've right now I'm
2:31:31
focused most of my workouts on on fighting so so Jiu Jitsu and MMA
2:31:39
um but I don't know I mean maybe if you're a professional you can do that every day I
2:31:44
can't I just get you know it's too many too many bruises and things that you need to recover from so I do that you
2:31:50
know three to four times a week and then um and then the other day is
2:31:56
um I just try to do a mix of things like just cardio conditioning strength building Mobility
2:32:02
um so you try to do something physical every day yeah I try to unless I'm just so tired that I just need to
2:32:07
need to relax but then I'll still try to like go for a walk or something I mean even here um I don't know have you been on the
2:32:14
roof here yet no we'll go on the roof after those things but it's like we designed this this building and I I put
2:32:19
a park on the roof so that way that's like my meetings when I'm just doing kind of a one-on-one or talking to a
2:32:24
couple of people I'm I I have a very hard time just sitting I feel like it gets super stiff it like feels really
2:32:30
bad um but I don't know I being physical is
2:32:35
very important to me I think it's um I do not believe this gets to the question about AI
2:32:41
I don't think that a being is just a mind um and I think we're we're kind of meant
2:32:46
to do things and like physically and and a lot of the sensations that we feel are
2:32:54
um are are connected to that and I think that that's a lot of what makes you a human is is basically you know having
2:33:00
those having you know that set of Sensations and
2:33:05
experiences around that coupled with a mind to reason about them
2:33:11
um but I don't know I I think it's important for balance to
2:33:17
to kind of get out challenge yourself in different ways learn different skills clear your mind do you think
Embodied AGI
2:33:25
AI in order to become super intelligent in AGI should have a body
2:33:31
it depends on on what the goal is I think that there's this assumption
2:33:37
in that question that intelligence intelligence should be kind
2:33:43
of person-like whereas you know as we were just talking about
2:33:48
um you can have these greater than single human intelligent organisms like
2:33:53
the stock market which obviously do not have bodies and do not speak a language right and like you know and and just
2:33:59
kind of have their own system um but
2:34:06
so I don't know my guess is um it will there will be limits to what A system that is purely an intelligence
2:34:12
can understand about the Human Condition without having the same not just senses
2:34:18
but like our bodies change as we get older right and we kind of evolve and
2:34:25
I think that those very subtle physical changes
2:34:31
just drive a lot of social patterns and behavior around like when you choose to
2:34:36
have kids right like just like all these you know that's not even subtle that's a major one right but like um you know how you design things around
2:34:42
the house um so yeah I mean I think I think it would if the goal is to understand
2:34:48
people as much as possible I think I think that that's trying to model those Sensations is
2:34:54
probably somewhat important but I think there's a lot of value that can be created by having intelligence even that that is that is separate from that is a
2:35:01
separate thing uh so one of the features of being human is that we're mortal we
2:35:07
die uh we've talked about AI a lot about potentially replicas of ourselves uh do
2:35:14
you think there will be AI replicas of you and me that persists long after we're gone that family and loved ones can talk to
2:35:24
I think we'll have the capacity to do something like that and I think one of the big questions
2:35:30
that we've had to struggle with in the context of social networks is who gets to make that
2:35:37
um and you know and my answer to that you know in the context of the work that we're doing is that that should be your
2:35:43
choice right I don't think anyone should be able to choose to make a Lex spot that people can
2:35:50
can choose to talk to and get to train that yeah and we've kind of we have this precedent of making some of these calls
2:35:56
where I mean someone can create a page for uh a Lex fan club but you can't create a
2:36:04
page and say that you relax yes right um so I think that this similarly I think
2:36:11
I mean maybe you know someone maybe can make a should be able to make an AI That's um that's a Lex admirer that
2:36:17
someone can talk to but I think it should ultimately be your call whether there is a Lex AI well I'm open sourcing
2:36:25
The Lex so uh you're a man of Faith what what
Faith
2:36:32
role has Faith played in your life and your understanding of the world and the understanding of your own life
2:36:37
and your understanding of uh your work and how to
2:36:42
your work impacts the world yeah I think that there's a few
2:36:48
different parts of this that are relevant um there's sort of a philosophical part and
2:36:53
there's a cultural part and one of the most basic lessons is uh
2:36:59
right at the beginning of Genesis right it's like God creates the Earth and creates people and creates people in
2:37:05
God's image and there's the question of you know what does that mean and all the only context that you have about God at
2:37:12
that point in the Old Testament is that he's God has created things so I I always thought that like one of the
2:37:17
interesting lessons from that is that there's a virtue in creating things
2:37:24
that is like whether it's artistic or whether you're building things that are functionally
2:37:30
useful for other people um I've got that by itself
2:37:37
is a good and I that kind of drives a lot of how I think
2:37:44
about morality and my my personal philosophy around like what what is a good life
2:37:50
right it's I think it's one where you're you know helping the people around you
2:37:56
and your being a kind of positive creative force
2:38:01
in the world that is helping to you know bring new things into the world whether they're you know amazing other people
2:38:08
kids or um
2:38:13
or just leading to the creation of different things that would have been possible otherwise and so that's a value
2:38:18
for me that that that matters deeply and I I just I mean I just love you know spending time with the kids and seeing
2:38:24
that they sort of you know trying to impart this value to them then um it's like I mean nothing makes me
2:38:31
happier than like when I come home from work and you know I see like my my daughter's like building
2:38:37
Legos on the table or something it's like all right I did that when I was a kid right so many other people were doing this and like I hope you don't
2:38:44
lose that Spirit where when you you kind of grow up and you want to just continue building different things no matter what
2:38:50
it is um to me that's a lot of what matters that's the philosophical piece I think
2:38:56
the cultural piece is just about community and values and that part of part of things I think has just become a
2:39:02
lot more important to me since I've had kids um you know it's almost autopilot when you're a kid
2:39:07
you're in the kind of getting imparted two phase of your life but and and I didn't really think about
2:39:13
religion that much for a while um you know I was in college
2:39:19
you know before I before I had kids and then I think having kids has this way of
2:39:24
really making you think about what traditions you want to impart and um and how you want to celebrate and
2:39:32
like what what balance you want in your life and I'm in a bunch of the questions that you've asked and a bunch of the things
2:39:38
that we're talking about just the irony of the curtains coming down
2:39:44
as we're talking about mortality once again yeah same as last time this is
2:39:49
just just that the Universe Works in we are definitely living in a simulation but but go ahead um Community tradition
2:39:57
and the values the faith well I mean religion is still a lot of the topics that we've talked about today are around
2:40:03
how do you how do you balance
2:40:09
you know whether it's running a company or or different responsibilities with this
2:40:16
how do you how do you kind of balance that and I I always also just think that it's very grounding to just
2:40:24
believe that there's something that is much bigger than you that is guiding things
2:40:29
at uh amongst other things gives gives you a bit of humility
2:40:36
um as you pursue that Spirit of creating
2:40:41
that you you spoke to creating Beauty in the world and as Dostoevsky said Beauty will save the world
2:40:47
uh Mark I'm a huge fan of yours um honored to be able to call you a
2:40:53
friend and I am looking forward to uh um both kicking your ass and you kicking
2:40:58
my ass on the mat tomorrow in Jiu Jitsu uh this this incredible Sport and art
2:41:04
that we both uh we'll both participate in thank you so much for talking today thank you for everything you're doing and so many
2:41:10
exciting Realms of technology and human life I can't wait to talk to you again
2:41:15
in the metaverse thank you thanks for listening to this conversation with Mark Zuckerberg to
2:41:21
support this podcast please check out our sponsors in the description and now let me leave you some words from Isaac
2:41:27
Asimov it is change continuing change inevitable change that is the dominant
2:41:34
factor in society today no sensible decision can be made any longer without taking into account not
2:41:41
only the world as it is but the world as it will be thank you for listening and hope to see
2:41:48
you next time